{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn_crfsuite datasets evaluate seqeval tabulate -q"
      ],
      "metadata": {
        "id": "AaAy6lL9ZPTW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9f854df99f9c45718acd59149634033e",
            "62e29914206a40599011b05ccf0b30dd",
            "4170da5d613e433eb9e27f8d9160648f",
            "dd61a0a12971455ebe31d9448605960c",
            "f8f8b41b46c1402490d9b678217992c7",
            "c27ed6157fce415290097511ec65910e",
            "d6a53b0e24de47a18b628fd704270edc",
            "f4f54be9be984e8c80105052ec7f335c",
            "fda57aa78ded4360b17656fb4644c895",
            "db76124aeadf4ad4bd5196d715ad98c7",
            "69c7e17921634335a4bc791c0f4e578b",
            "cb55b8e81cb54294aa7da676f2c0691d",
            "c495309b11304e9eb5355966f52cf97f",
            "b40098b8f56544a281eda3a15ef59893",
            "5cca553c2b654eb8b2761ebd123fbb18",
            "3c2feae962124aa6842037a8dce18e5d",
            "3beb90f04af44d31a491684bd281188c",
            "bf529e7d5f37450686fff3f756b024af",
            "70be7a0525914b2fa066062a0487fa67",
            "33cb9a2330244ea3bb8f13ee58f8f411",
            "7500f86e916c468d870d619b4039a701",
            "ad34d65951474e6783a704a52ce06561",
            "322f8080212a4b0fb511d8d7533ad2d0",
            "cd4529736da44676858a5c4e7968a58b",
            "05b9602a02da4e22b9442bea7dc1f6af",
            "09505ab48afa4f4d99eaf4564da232a7",
            "7e02312294974e2481af9028337eeffa",
            "4852bfae917645d5a6ae41c65bdfed5f",
            "d90666635799451cb7dc3da8913f829f",
            "f3c57ab96e0d4dfc8f69ec30683ea0d7",
            "77a2b8a78ab14e08aedd682957a59bd2",
            "4f49f45fd1a5467dba04860826047f37",
            "c349b1c97aa14b45a7af90ca46992fba",
            "2631a8c9d8c147698272fe004c60c94f",
            "014d55469f554a9daea56778250c5931",
            "56939d9ec03e48f4be9866d5972cccf1",
            "32b0333aae7f4a2daab76c3942786817",
            "6d67207ab0714a97b3bd133d84b11c0c",
            "269c7e13eed24b9b90e827a908fb09e6",
            "4200e1761a9f42348c3c09bee2b11b5f",
            "bcac5f4e333942ceabe4f2644588de43",
            "da610495646d466d9353cc0ca9096d0b",
            "83fb75cdab4b4b7b8d778f88e023362a",
            "5884d9b054844353aa10a239293b12aa",
            "50971b6f60ae4ef3b0ebfe963a1ee859",
            "2333294cd47f475384bcffc610dad663",
            "efbbeff874574e39980540ad5c36d5fa",
            "c506226e150c487889bf2de7ef45bc7c",
            "7ac547419f1140bc9a575cd303523ef4",
            "03625d7b24434168b0f8c47a7f31dfa1",
            "8a776547ca1d4cc09fd2e991d2db742f",
            "f26ba613d4124708b03cb77739954718",
            "123f4867421a41418556b5178453a607",
            "f9335e56585e42f4a0b09ff1a5fa6963",
            "6e39ced41bbc47ea9b8e2260bfa0887f",
            "2d409a839b2d490b805cab1f3b6460b4",
            "9d28b03e87734b72b753a93643ae9639",
            "a0170e4d7fb444ce95d7f8cde254ca4e",
            "22769f4b2ae341e2afb06a051ff57590",
            "9c35262d72bc4164bdd0924012cedf96",
            "8b832586c4da464790d8ed1ed75cb413",
            "fd032c791aff4382b7c85547da42bdad",
            "8b5741ed517645d79f8ad83ea1b0407c",
            "f5da5b87501b4c5d9729b9cc17021fd0",
            "9de2e1c17aca41359a99a6b918adcc3b",
            "6951bd2936d546a6850f06fe68a68a7a",
            "0b35af7f7a784951b21badadb93b5edc",
            "38ad96b15bb3455ea5e19cb815f67ee2",
            "f2d4b596d8104f3aaf61d37c036f610e",
            "b15b5194f7654340a15454f1d5955b82",
            "309ce0a55c3d450fa2fcaf75d10cca3d",
            "df2c443e16d44d6ab61804622c690bc8",
            "87b48ace78a448c68f555772d03f73f5",
            "b6bca428c0d54ad6933b702d9a69050e",
            "7a03f1f65ec54a13b8c749d0abbcda59",
            "344db17b9bf1431787666596044e691b",
            "a1f61bcc8fdf4dfeb2b888e82ab7d555"
          ]
        },
        "id": "IzjtSFPGUK5l",
        "outputId": "87b760d4-f832-4e61-fb51-bafc3d4228ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading CoNLL2003 dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/12.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f854df99f9c45718acd59149634033e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "conll2003.py:   0%|          | 0.00/9.57k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb55b8e81cb54294aa7da676f2c0691d"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for conll2003 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/conll2003.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "322f8080212a4b0fb511d8d7533ad2d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2631a8c9d8c147698272fe004c60c94f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50971b6f60ae4ef3b0ebfe963a1ee859"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d409a839b2d490b805cab1f3b6460b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing data for CRF...\n",
            "Training CRF model...\n",
            "\n",
            "Evaluating CRF NER system...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b35af7f7a784951b21badadb93b5edc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CRF NER Evaluation Results\n",
            "+--------+-----------+--------+----------+---------+\n",
            "| Entity | Precision | Recall | F1 Score | Support |\n",
            "+--------+-----------+--------+----------+---------+\n",
            "|  LOC   |  0.8756   | 0.8735 |  0.8745  |  1668   |\n",
            "|  MISC  |  0.7731   | 0.7621 |  0.7676  |   702   |\n",
            "|  ORG   |  0.7936   | 0.7339 |  0.7626  |  1661   |\n",
            "|  PER   |  0.8479   | 0.8652 |  0.8564  |  1617   |\n",
            "+--------+-----------+--------+----------+---------+\n",
            "Overall Metrics\n",
            "Overall Precision: 0.8318\n",
            "Overall Recall: 0.8162\n",
            "Overall F1 Score: 0.8239\n",
            "Overall Accuracy: 0.9617\n",
            "\n",
            "Generating detailed classification report...\n",
            "CRF NER Classification Report (seqeval)\n",
            "{'LOC': {'precision': np.float64(0.8756009615384616), 'recall': np.float64(0.8735011990407674), 'f1': np.float64(0.8745498199279712), 'number': np.int64(1668)}, 'MISC': {'precision': np.float64(0.773121387283237), 'recall': np.float64(0.7621082621082621), 'f1': np.float64(0.7675753228120517), 'number': np.int64(702)}, 'ORG': {'precision': np.float64(0.7936197916666666), 'recall': np.float64(0.7338952438290187), 'f1': np.float64(0.762589928057554), 'number': np.int64(1661)}, 'PER': {'precision': np.float64(0.8478787878787879), 'recall': np.float64(0.865182436611008), 'f1': np.float64(0.8564432200795837), 'number': np.int64(1617)}, 'overall_precision': np.float64(0.8318296643810899), 'overall_recall': np.float64(0.8162181303116147), 'overall_f1': np.float64(0.8239499553172476), 'overall_accuracy': 0.961731452568106}\n",
            "\n",
            "Analyzing CRF model features...\n",
            "Top State Features by Label:\n",
            "word.prefix-3:PER\n",
            "  B-LOC: 0.2062\n",
            "word[-3:]:PER\n",
            "  I-MISC: 0.0376\n",
            "  O: -0.0164\n",
            "word.suffix-3:PER\n",
            "  I-MISC: 0.0376\n",
            "  O: -0.0164\n",
            "Top Transition Features:\n",
            "  O -> I-ORG: -5.5974\n",
            "  B-MISC -> I-ORG: -5.0817\n",
            "  B-LOC -> I-ORG: -5.0770\n",
            "  O -> I-MISC: -4.9167\n",
            "  B-PER -> B-PER: -4.8862\n",
            "  I-LOC -> I-LOC: 4.3835\n",
            "  B-LOC -> I-LOC: 4.3467\n",
            "  B-PER -> I-PER: 4.3147\n",
            "  O -> I-PER: -3.9627\n",
            "  B-LOC -> I-MISC: -3.9185\n",
            "  I-ORG -> I-PER: -3.8912\n",
            "  B-ORG -> I-MISC: -3.8564\n",
            "  O -> I-LOC: -3.8436\n",
            "  I-ORG -> B-LOC: -3.7714\n",
            "  I-PER -> B-PER: -3.7653\n",
            "  I-MISC -> I-MISC: 3.7510\n",
            "  I-ORG -> B-ORG: -3.7500\n",
            "  B-ORG -> B-PER: -3.7496\n",
            "  B-LOC -> B-PER: -3.7247\n",
            "  B-ORG -> I-ORG: 3.7203\n"
          ]
        }
      ],
      "source": [
        "# CRF-based NER model for CoNLL-2003 data with comprehensive evaluation\n",
        "# --------------------------------------------------------------------\n",
        "import numpy as np\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import metrics\n",
        "from collections import Counter\n",
        "from datasets import load_dataset\n",
        "from evaluate import load\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Feature extraction functions for CRF\n",
        "# ----------------------------------\n",
        "def word2features(sent, i):\n",
        "    \"\"\"Extract features from word at position i.\"\"\"\n",
        "    word = sent[i]\n",
        "\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        'word[-3:]': word[-3:],\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'word.contains_hyphen': '-' in word,\n",
        "        'word.contains_dot': '.' in word,\n",
        "        'word.length': len(word),\n",
        "        'word.prefix-2': word[:2],\n",
        "        'word.prefix-3': word[:3],\n",
        "        'word.suffix-2': word[-2:],\n",
        "        'word.suffix-3': word[-3:],\n",
        "        'word.contains_digit': any(char.isdigit() for char in word),\n",
        "        'word.contains_uppercase': any(char.isupper() for char in word),\n",
        "        'word.is_alphanumeric': word.isalnum(),\n",
        "        'word.is_alphabetic': word.isalpha(),\n",
        "    }\n",
        "\n",
        "    # Context features - previous word\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "            '-1:word.isdigit()': word1.isdigit(),\n",
        "            '-1:word.prefix-2': word1[:2],\n",
        "            '-1:word.suffix-2': word1[-2:],\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    # Context features - next word\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1]\n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "            '+1:word.isdigit()': word1.isdigit(),\n",
        "            '+1:word.prefix-2': word1[:2],\n",
        "            '+1:word.suffix-2': word1[-2:],\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    # Additional context features\n",
        "    if i > 1:\n",
        "        word2 = sent[i-2]\n",
        "        features.update({\n",
        "            '-2:word.lower()': word2.lower(),\n",
        "            '-2:word.istitle()': word2.istitle(),\n",
        "        })\n",
        "\n",
        "    if i < len(sent)-2:\n",
        "        word2 = sent[i+2]\n",
        "        features.update({\n",
        "            '+2:word.lower()': word2.lower(),\n",
        "            '+2:word.istitle()': word2.istitle(),\n",
        "        })\n",
        "\n",
        "    return features\n",
        "\n",
        "def sent2features(sent):\n",
        "    \"\"\"Convert sentence to list of features.\"\"\"\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(tags, id_to_label):\n",
        "    \"\"\"Convert tags to labels.\"\"\"\n",
        "    return [id_to_label(tag) for tag in tags]\n",
        "\n",
        "# Main CRF NER class\n",
        "# -----------------\n",
        "class CRFNER:\n",
        "    def __init__(self, c1=0.1, c2=0.1, max_iterations=100):\n",
        "        self.crf = sklearn_crfsuite.CRF(\n",
        "            algorithm='lbfgs',\n",
        "            c1=c1,\n",
        "            c2=c2,\n",
        "            max_iterations=max_iterations,\n",
        "            all_possible_transitions=True\n",
        "        )\n",
        "        self.allowed_entities = {\"PER\", \"LOC\", \"ORG\", \"MISC\"}\n",
        "\n",
        "    def train(self, X_train, y_train):\n",
        "        \"\"\"Train CRF model.\"\"\"\n",
        "        self.crf.fit(X_train, y_train)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        \"\"\"Predict using CRF model.\"\"\"\n",
        "        return self.crf.predict(X_test)\n",
        "\n",
        "    def get_transition_features(self):\n",
        "        \"\"\"Get learned transition features.\"\"\"\n",
        "        if hasattr(self.crf, 'transition_features_'):\n",
        "            return dict(self.crf.transition_features_)\n",
        "        return {}\n",
        "\n",
        "    def get_state_features(self):\n",
        "        \"\"\"Get learned state features.\"\"\"\n",
        "        if hasattr(self.crf, 'state_features_'):\n",
        "            return dict(self.crf.state_features_)\n",
        "        return {}\n",
        "\n",
        "# Prepare data for CRF\n",
        "# -------------------\n",
        "def prepare_crf_data(dataset):\n",
        "    \"\"\"Prepare CoNLL data for CRF training and testing.\"\"\"\n",
        "    id_to_label = dataset[\"train\"].features[\"ner_tags\"].feature.int2str\n",
        "\n",
        "    # Prepare training data\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    for example in dataset[\"train\"]:\n",
        "        tokens = example[\"tokens\"]\n",
        "        tags = example[\"ner_tags\"]\n",
        "        X_train.append(sent2features(tokens))\n",
        "        y_train.append(sent2labels(tags, id_to_label))\n",
        "\n",
        "    # Prepare test data\n",
        "    X_test = []\n",
        "    y_test = []\n",
        "    for example in dataset[\"test\"]:\n",
        "        tokens = example[\"tokens\"]\n",
        "        tags = example[\"ner_tags\"]\n",
        "        X_test.append(sent2features(tokens))\n",
        "        y_test.append(sent2labels(tags, id_to_label))\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "# CRF evaluation with seqeval\n",
        "# -------------------------\n",
        "def evaluate_crf_ner_system(crf_model, X_test, y_test):\n",
        "    \"\"\"Evaluate CRF NER system using seqeval.\"\"\"\n",
        "    # Get predictions\n",
        "    y_pred = crf_model.predict(X_test)\n",
        "\n",
        "    # Evaluate using seqeval\n",
        "    metric = load(\"seqeval\")\n",
        "    results = metric.compute(predictions=y_pred, references=y_test)\n",
        "\n",
        "    # Display results\n",
        "    print(\"CRF NER Evaluation Results\")\n",
        "\n",
        "    # Create detailed table for per-entity results\n",
        "    crf_table = []\n",
        "    for entity, metrics in results.items():\n",
        "        if isinstance(metrics, dict) and any(e in entity for e in crf_model.allowed_entities):\n",
        "            crf_table.append([\n",
        "                entity,\n",
        "                f\"{metrics['precision']:.4f}\",\n",
        "                f\"{metrics['recall']:.4f}\",\n",
        "                f\"{metrics['f1']:.4f}\",\n",
        "                metrics['number']\n",
        "            ])\n",
        "\n",
        "    print(tabulate(crf_table, headers=[\"Entity\", \"Precision\", \"Recall\", \"F1 Score\", \"Support\"], tablefmt=\"pretty\"))\n",
        "\n",
        "    # Overall results\n",
        "    print(f\"Overall Metrics\")\n",
        "    print(f\"Overall Precision: {results['overall_precision']:.4f}\")\n",
        "    print(f\"Overall Recall: {results['overall_recall']:.4f}\")\n",
        "    print(f\"Overall F1 Score: {results['overall_f1']:.4f}\")\n",
        "    print(f\"Overall Accuracy: {results['overall_accuracy']:.4f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Generate detailed seqeval report\n",
        "# ------------------------------\n",
        "def generate_crf_seqeval_report(crf_model, X_test, y_test):\n",
        "    \"\"\"Generate detailed seqeval classification report for CRF.\"\"\"\n",
        "    # Get predictions\n",
        "    y_pred = crf_model.predict(X_test)\n",
        "\n",
        "    # Generate seqeval classification report\n",
        "    metric = load(\"seqeval\")\n",
        "    print(\"CRF NER Classification Report (seqeval)\")\n",
        "    print(metric.compute(predictions=y_pred, references=y_test, mode='strict', scheme='IOB2'))\n",
        "\n",
        "    return y_pred, y_test\n",
        "\n",
        "# Analyze CRF model features\n",
        "# ------------------------\n",
        "def analyze_crf_features(crf_model):\n",
        "    \"\"\"Analyze important features learned by CRF.\"\"\"\n",
        "    # Get state and transition features\n",
        "    state_features = crf_model.get_state_features()\n",
        "    transition_features = crf_model.get_transition_features()\n",
        "\n",
        "    # Top state features for each label\n",
        "    print(\"Top State Features by Label:\")\n",
        "    label_features = {}\n",
        "\n",
        "    for (label, feature), weight in state_features.items():\n",
        "        if label not in label_features:\n",
        "            label_features[label] = []\n",
        "        label_features[label].append((feature, weight))\n",
        "\n",
        "    # Sort and display top features for each label\n",
        "    for label, features in label_features.items():\n",
        "        if any(e in label for e in [\"PER\", \"LOC\", \"ORG\", \"MISC\"]):\n",
        "            print(f\"{label}\")\n",
        "            top_features = sorted(features, key=lambda x: abs(x[1]), reverse=True)[:10]\n",
        "            for feature, weight in top_features:\n",
        "                print(f\"  {feature}: {weight:.4f}\")\n",
        "\n",
        "    # Top transition features\n",
        "    print(\"Top Transition Features:\")\n",
        "    top_transitions = sorted(transition_features.items(), key=lambda x: abs(x[1]), reverse=True)[:20]\n",
        "    for (from_label, to_label), weight in top_transitions:\n",
        "        print(f\"  {from_label} -> {to_label}: {weight:.4f}\")\n",
        "\n",
        "# Main execution function for CRF evaluation\n",
        "# ----------------------------------------\n",
        "def run_crf_evaluation():\n",
        "    \"\"\"Run CRF model training and evaluation.\"\"\"\n",
        "    # Load dataset\n",
        "    print(\"Loading CoNLL2003 dataset...\")\n",
        "    dataset = load_dataset(\"conll2003\")\n",
        "\n",
        "    # Prepare data\n",
        "    print(\"Preparing data for CRF...\")\n",
        "    X_train, y_train, X_test, y_test = prepare_crf_data(dataset)\n",
        "\n",
        "    # Initialize and train CRF model\n",
        "    print(\"Training CRF model...\")\n",
        "    crf_model = CRFNER(c1=0.1, c2=0.1, max_iterations=100)\n",
        "    crf_model.train(X_train, y_train)\n",
        "\n",
        "    # Evaluate model\n",
        "    print(\"\\nEvaluating CRF NER system...\")\n",
        "    results = evaluate_crf_ner_system(crf_model, X_test, y_test)\n",
        "\n",
        "    # Generate detailed classification report\n",
        "    print(\"\\nGenerating detailed classification report...\")\n",
        "    generate_crf_seqeval_report(crf_model, X_test, y_test)\n",
        "\n",
        "    # Analyze model features\n",
        "    print(\"\\nAnalyzing CRF model features...\")\n",
        "    analyze_crf_features(crf_model)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run the CRF evaluation\n",
        "if __name__ == \"__main__\":\n",
        "    run_crf_evaluation()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from termcolor import colored\n",
        "from tabulate import tabulate\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def analyze_examples(crf_model, dataset, num_examples=10):\n",
        "    \"\"\"Analyze CRF predictions on specific examples with better formatting.\"\"\"\n",
        "    id_to_label = dataset[\"train\"].features[\"ner_tags\"].feature.int2str\n",
        "    test_examples = dataset[\"test\"]\n",
        "\n",
        "    print(\"Analyzing Specific Examples:\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    found_examples = 0\n",
        "\n",
        "    for i in range(len(test_examples)):\n",
        "        if found_examples >= num_examples:\n",
        "            break\n",
        "\n",
        "        tokens = test_examples[i][\"tokens\"]\n",
        "        true_tags = [id_to_label(tag) for tag in test_examples[i][\"ner_tags\"]]\n",
        "\n",
        "        # Get CRF predictions\n",
        "        features = sent2features(tokens)\n",
        "        pred_tags = crf_model.predict([features])[0]\n",
        "\n",
        "        # Check if any prediction is different from the true label\n",
        "        has_mismatches = any(true != pred for true, pred in zip(true_tags, pred_tags))\n",
        "\n",
        "        # Always show examples with mismatches, or until we have enough examples\n",
        "        if has_mismatches or found_examples < num_examples:\n",
        "            found_examples += 1\n",
        "            print(f\"Example {found_examples}:\")\n",
        "            print(f\"Sentence: {' '.join(tokens)}\")\n",
        "\n",
        "            # Create alignment table\n",
        "            table_data = []\n",
        "            for j, (token, true, pred) in enumerate(zip(tokens, true_tags, pred_tags)):\n",
        "\n",
        "                table_data.append([j, token, true])\n",
        "\n",
        "            print(\"\\n\" + tabulate(table_data, headers=[\"Index\", \"Token\", \"True Label\", \"Predicted Label\"], tablefmt=\"simple\"))\n",
        "\n",
        "            # Extract entities\n",
        "            true_entities = extract_entities(tokens, true_tags)\n",
        "            pred_entities = extract_entities(tokens, pred_tags)\n",
        "\n",
        "            print(f\"\\nTrue Entities: {true_entities}\")\n",
        "            print(f\"Predicted Entities: {pred_entities}\")\n",
        "\n",
        "            # Analyze feature contributions for mismatches\n",
        "            analyze_feature_contributions(crf_model, tokens, features, true_tags, pred_tags)\n",
        "            print(\"-\" * 80)\n",
        "\n",
        "def extract_entities(tokens, tags):\n",
        "    \"\"\"Extract entity spans from tokens and tags.\"\"\"\n",
        "    entities = []\n",
        "    current_entity = None\n",
        "    current_type = None\n",
        "\n",
        "    for i, (token, tag) in enumerate(zip(tokens, tags)):\n",
        "        if tag.startswith('B-'):\n",
        "            if current_entity:\n",
        "                entities.append((current_type, ' '.join(current_entity)))\n",
        "            current_entity = [token]\n",
        "            current_type = tag[2:]\n",
        "        elif tag.startswith('I-') and current_entity:\n",
        "            current_entity.append(token)\n",
        "        else:\n",
        "            if current_entity:\n",
        "                entities.append((current_type, ' '.join(current_entity)))\n",
        "                current_entity = None\n",
        "                current_type = None\n",
        "\n",
        "    if current_entity:\n",
        "        entities.append((current_type, ' '.join(current_entity)))\n",
        "\n",
        "    return entities\n",
        "\n",
        "def analyze_feature_contributions(crf_model, tokens, features, true_tags, pred_tags):\n",
        "    \"\"\"Analyze which features contributed to each prediction.\"\"\"\n",
        "    for i, (token, true, pred) in enumerate(zip(tokens, true_tags, pred_tags)):\n",
        "        if true != pred:\n",
        "            print(f\"Token '{token}' - True: {true}, Predicted: {pred}\")\n",
        "\n",
        "            # Get top features for this token\n",
        "            token_features = features[i]\n",
        "            feature_weights = {}\n",
        "\n",
        "            # Calculate feature contributions\n",
        "            for fname, fval in token_features.items():\n",
        "                if (pred, fname) in crf_model.crf.state_features_:\n",
        "                    weight = crf_model.crf.state_features_[(pred, fname)]\n",
        "                    feature_weights[fname] = weight * fval\n",
        "\n",
        "                # Also check for true label weights for comparison\n",
        "                if (true, fname) in crf_model.crf.state_features_:\n",
        "                    true_weight = crf_model.crf.state_features_[(true, fname)]\n",
        "                    # Store as tuple (pred_contrib, true_contrib)\n",
        "                    if fname not in feature_weights:\n",
        "                        feature_weights[fname] = (0, true_weight * fval)\n",
        "                    else:\n",
        "                        feature_weights[fname] = (feature_weights[fname], true_weight * fval)\n",
        "\n",
        "            # Sort and display top contributing features\n",
        "            sorted_features = sorted(feature_weights.items(),\n",
        "                                  key=lambda x: abs(x[1] if isinstance(x[1], float) else x[1][0]),\n",
        "                                  reverse=True)[:5]\n",
        "\n",
        "            print(\"Top contributing features (predicted value contribution, true value contribution):\")\n",
        "            for fname, contrib in sorted_features:\n",
        "                if isinstance(contrib, tuple):\n",
        "                    print(f\"  {fname}: predicted={contrib[0]:.4f}, true={contrib[1]:.4f}\")\n",
        "                else:\n",
        "                    print(f\"  {fname}: {contrib:.4f}\")\n",
        "\n",
        "def analyze_confidence_scores(crf_model, X_test, num_examples=5):\n",
        "    \"\"\"Analyze prediction confidence scores with better formatting.\"\"\"\n",
        "    print(\"Analyzing Prediction Confidence:\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for i in range(min(num_examples, len(X_test))):\n",
        "        features = X_test[i]\n",
        "        # Get marginal probabilities\n",
        "        marginals = crf_model.crf.predict_marginals_single(features)\n",
        "        predictions = crf_model.predict([features])[0]\n",
        "\n",
        "        print(f\"Example {i+1}:\")\n",
        "\n",
        "        # Create confidence visualization\n",
        "        table_data = []\n",
        "        for j, (pred, probs) in enumerate(zip(predictions, marginals)):\n",
        "            # Get top 3 probable labels\n",
        "            sorted_probs = sorted(probs.items(), key=lambda x: x[1], reverse=True)[:3]\n",
        "            top_labels = ', '.join([f\"{l}({p:.3f})\" for l, p in sorted_probs])\n",
        "\n",
        "            # Highlight low confidence predictions\n",
        "            confidence = probs[pred]\n",
        "            confidence_str = f\"{confidence:.6f}\" if confidence < 0.7 else f\"{confidence:.6f}\"\n",
        "\n",
        "            table_data.append([j, pred, confidence_str, top_labels])\n",
        "\n",
        "        print(tabulate(table_data, headers=[\"Position\", \"Predicted\", \"Confidence\", \"Top 3 Labels\"], tablefmt=\"simple\"))\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "def run_detailed_error_analysis(crf_model, dataset):\n",
        "    \"\"\"Run detailed error analysis on the CRF model predictions.\"\"\"\n",
        "    id_to_label = dataset[\"train\"].features[\"ner_tags\"].feature.int2str\n",
        "    test_examples = dataset[\"test\"]\n",
        "\n",
        "    # Error pattern analysis\n",
        "    error_patterns = {\n",
        "        'LOC_as_PER': 0,\n",
        "        'PER_as_LOC': 0,\n",
        "        'LOC_as_ORG': 0,\n",
        "        'ORG_as_LOC': 0,\n",
        "        'MISC_as_ORG': 0,\n",
        "        'ORG_as_MISC': 0,\n",
        "        'entity_as_O': 0,\n",
        "        'O_as_entity': 0,\n",
        "        'boundary_errors': 0\n",
        "    }\n",
        "\n",
        "    total_errors = 0\n",
        "    total_tokens = 0\n",
        "\n",
        "    for example in test_examples:\n",
        "        tokens = example[\"tokens\"]\n",
        "        true_tags = [id_to_label(tag) for tag in example[\"ner_tags\"]]\n",
        "\n",
        "        # Get CRF predictions\n",
        "        features = sent2features(tokens)\n",
        "        pred_tags = crf_model.predict([features])[0]\n",
        "\n",
        "        total_tokens += len(tokens)\n",
        "\n",
        "        for true, pred in zip(true_tags, pred_tags):\n",
        "            if true != pred:\n",
        "                total_errors += 1\n",
        "\n",
        "                # Analyze error type\n",
        "                if true == 'O' and pred != 'O':\n",
        "                    error_patterns['O_as_entity'] += 1\n",
        "                elif true != 'O' and pred == 'O':\n",
        "                    error_patterns['entity_as_O'] += 1\n",
        "                elif true.endswith('LOC') and pred.endswith('PER'):\n",
        "                    error_patterns['LOC_as_PER'] += 1\n",
        "                elif true.endswith('PER') and pred.endswith('LOC'):\n",
        "                    error_patterns['PER_as_LOC'] += 1\n",
        "                elif true.endswith('LOC') and pred.endswith('ORG'):\n",
        "                    error_patterns['LOC_as_ORG'] += 1\n",
        "                elif true.endswith('ORG') and pred.endswith('LOC'):\n",
        "                    error_patterns['ORG_as_LOC'] += 1\n",
        "                elif true.endswith('MISC') and pred.endswith('ORG'):\n",
        "                    error_patterns['MISC_as_ORG'] += 1\n",
        "                elif true.endswith('ORG') and pred.endswith('MISC'):\n",
        "                    error_patterns['ORG_as_MISC'] += 1\n",
        "                elif true[0] != pred[0]:  # B/I mismatch\n",
        "                    error_patterns['boundary_errors'] += 1\n",
        "\n",
        "    # Print error analysis\n",
        "    print(\"Detailed Error Pattern Analysis:\")\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"Total tokens analyzed: {total_tokens}\")\n",
        "    print(f\"Total errors: {total_errors}\")\n",
        "    print(f\"Error rate: {total_errors/total_tokens*100:.2f}%\\n\")\n",
        "\n",
        "    print(\"Error patterns:\")\n",
        "    for pattern, count in sorted(error_patterns.items(), key=lambda x: x[1], reverse=True):\n",
        "        if count > 0:\n",
        "            percentage = count/total_errors*100\n",
        "            print(f\"  {pattern}: {count} ({percentage:.1f}% of errors)\")\n",
        "\n",
        "    return error_patterns, total_errors, total_tokens\n",
        "\n",
        "def run_crf_evaluation_with_analysis():\n",
        "    \"\"\"Run CRF model training, evaluation, and detailed analysis.\"\"\"\n",
        "    # Load dataset\n",
        "    print(\"Loading CoNLL2003 dataset...\")\n",
        "    dataset = load_dataset(\"conll2003\")\n",
        "\n",
        "    # Prepare data\n",
        "    print(\"Preparing data for CRF...\")\n",
        "    X_train, y_train, X_test, y_test = prepare_crf_data(dataset)\n",
        "\n",
        "    # Initialize and train CRF model\n",
        "    print(\"Training CRF model...\")\n",
        "    crf_model = CRFNER(c1=0.1, c2=0.1, max_iterations=100)\n",
        "    crf_model.train(X_train, y_train)\n",
        "\n",
        "    # Evaluate model\n",
        "    print(\"\\nEvaluating CRF NER system...\")\n",
        "    results = evaluate_crf_ner_system(crf_model, X_test, y_test)\n",
        "\n",
        "    # Generate detailed classification report\n",
        "    print(\"\\nGenerating detailed classification report...\")\n",
        "    generate_crf_seqeval_report(crf_model, X_test, y_test)\n",
        "\n",
        "    # Analyze model features\n",
        "    print(\"\\nAnalyzing CRF model features...\")\n",
        "    analyze_crf_features(crf_model)\n",
        "\n",
        "    # Analyze specific examples with better formatting\n",
        "    analyze_examples(crf_model, dataset, num_examples=10)\n",
        "\n",
        "    # Run detailed error analysis\n",
        "    run_detailed_error_analysis(crf_model, dataset)\n",
        "\n",
        "    # Analyze confidence scores with better formatting\n",
        "    analyze_confidence_scores(crf_model, X_test, num_examples=5)\n",
        "\n",
        "    return results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_crf_evaluation_with_analysis()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB_2RwxmaLqJ",
        "outputId": "7be0dd88-9a57-40d2-c3dd-fe9dfce478ef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading CoNLL2003 dataset...\n",
            "Preparing data for CRF...\n",
            "Training CRF model...\n",
            "\n",
            "Evaluating CRF NER system...\n",
            "CRF NER Evaluation Results\n",
            "+--------+-----------+--------+----------+---------+\n",
            "| Entity | Precision | Recall | F1 Score | Support |\n",
            "+--------+-----------+--------+----------+---------+\n",
            "|  LOC   |  0.8756   | 0.8735 |  0.8745  |  1668   |\n",
            "|  MISC  |  0.7731   | 0.7621 |  0.7676  |   702   |\n",
            "|  ORG   |  0.7936   | 0.7339 |  0.7626  |  1661   |\n",
            "|  PER   |  0.8479   | 0.8652 |  0.8564  |  1617   |\n",
            "+--------+-----------+--------+----------+---------+\n",
            "Overall Metrics\n",
            "Overall Precision: 0.8318\n",
            "Overall Recall: 0.8162\n",
            "Overall F1 Score: 0.8239\n",
            "Overall Accuracy: 0.9617\n",
            "\n",
            "Generating detailed classification report...\n",
            "CRF NER Classification Report (seqeval)\n",
            "{'LOC': {'precision': np.float64(0.8756009615384616), 'recall': np.float64(0.8735011990407674), 'f1': np.float64(0.8745498199279712), 'number': np.int64(1668)}, 'MISC': {'precision': np.float64(0.773121387283237), 'recall': np.float64(0.7621082621082621), 'f1': np.float64(0.7675753228120517), 'number': np.int64(702)}, 'ORG': {'precision': np.float64(0.7936197916666666), 'recall': np.float64(0.7338952438290187), 'f1': np.float64(0.762589928057554), 'number': np.int64(1661)}, 'PER': {'precision': np.float64(0.8478787878787879), 'recall': np.float64(0.865182436611008), 'f1': np.float64(0.8564432200795837), 'number': np.int64(1617)}, 'overall_precision': np.float64(0.8318296643810899), 'overall_recall': np.float64(0.8162181303116147), 'overall_f1': np.float64(0.8239499553172476), 'overall_accuracy': 0.961731452568106}\n",
            "\n",
            "Analyzing CRF model features...\n",
            "Top State Features by Label:\n",
            "word.prefix-3:PER\n",
            "  B-LOC: 0.2062\n",
            "word[-3:]:PER\n",
            "  I-MISC: 0.0376\n",
            "  O: -0.0164\n",
            "word.suffix-3:PER\n",
            "  I-MISC: 0.0376\n",
            "  O: -0.0164\n",
            "Top Transition Features:\n",
            "  O -> I-ORG: -5.5974\n",
            "  B-MISC -> I-ORG: -5.0817\n",
            "  B-LOC -> I-ORG: -5.0770\n",
            "  O -> I-MISC: -4.9167\n",
            "  B-PER -> B-PER: -4.8862\n",
            "  I-LOC -> I-LOC: 4.3835\n",
            "  B-LOC -> I-LOC: 4.3467\n",
            "  B-PER -> I-PER: 4.3147\n",
            "  O -> I-PER: -3.9627\n",
            "  B-LOC -> I-MISC: -3.9185\n",
            "  I-ORG -> I-PER: -3.8912\n",
            "  B-ORG -> I-MISC: -3.8564\n",
            "  O -> I-LOC: -3.8436\n",
            "  I-ORG -> B-LOC: -3.7714\n",
            "  I-PER -> B-PER: -3.7653\n",
            "  I-MISC -> I-MISC: 3.7510\n",
            "  I-ORG -> B-ORG: -3.7500\n",
            "  B-ORG -> B-PER: -3.7496\n",
            "  B-LOC -> B-PER: -3.7247\n",
            "  B-ORG -> I-ORG: 3.7203\n",
            "Analyzing Specific Examples:\n",
            "--------------------------------------------------------------------------------\n",
            "Example 1:\n",
            "Sentence: SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRISE DEFEAT .\n",
            "\n",
            "  Index  Token     True Label\n",
            "-------  --------  ------------\n",
            "      0  SOCCER    O\n",
            "      1  -         O\n",
            "      2  JAPAN     B-LOC\n",
            "      3  GET       O\n",
            "      4  LUCKY     O\n",
            "      5  WIN       O\n",
            "      6  ,         O\n",
            "      7  CHINA     B-PER\n",
            "      8  IN        O\n",
            "      9  SURPRISE  O\n",
            "     10  DEFEAT    O\n",
            "     11  .         O\n",
            "\n",
            "True Entities: [('LOC', 'JAPAN'), ('PER', 'CHINA')]\n",
            "Predicted Entities: [('PER', 'JAPAN'), ('LOC', 'CHINA')]\n",
            "Token 'JAPAN' - True: B-LOC, Predicted: B-PER\n",
            "Top contributing features (predicted value contribution, true value contribution):\n",
            "Token 'CHINA' - True: B-PER, Predicted: B-LOC\n",
            "Top contributing features (predicted value contribution, true value contribution):\n",
            "--------------------------------------------------------------------------------\n",
            "Example 2:\n",
            "Sentence: Nadim Ladki\n",
            "\n",
            "  Index  Token    True Label\n",
            "-------  -------  ------------\n",
            "      0  Nadim    B-PER\n",
            "      1  Ladki    I-PER\n",
            "\n",
            "True Entities: [('PER', 'Nadim Ladki')]\n",
            "Predicted Entities: [('PER', 'Nadim Ladki')]\n",
            "--------------------------------------------------------------------------------\n",
            "Example 3:\n",
            "Sentence: AL-AIN , United Arab Emirates 1996-12-06\n",
            "\n",
            "  Index  Token       True Label\n",
            "-------  ----------  ------------\n",
            "      0  AL-AIN      B-LOC\n",
            "      1  ,           O\n",
            "      2  United      B-LOC\n",
            "      3  Arab        I-LOC\n",
            "      4  Emirates    I-LOC\n",
            "      5  1996-12-06  O\n",
            "\n",
            "True Entities: [('LOC', 'AL-AIN'), ('LOC', 'United Arab Emirates')]\n",
            "Predicted Entities: [('LOC', 'AL-AIN'), ('LOC', 'United Arab Emirates')]\n",
            "--------------------------------------------------------------------------------\n",
            "Example 4:\n",
            "Sentence: Japan began the defence of their Asian Cup title with a lucky 2-1 win against Syria in a Group C championship match on Friday .\n",
            "\n",
            "  Index  Token         True Label\n",
            "-------  ------------  ------------\n",
            "      0  Japan         B-LOC\n",
            "      1  began         O\n",
            "      2  the           O\n",
            "      3  defence       O\n",
            "      4  of            O\n",
            "      5  their         O\n",
            "      6  Asian         B-MISC\n",
            "      7  Cup           I-MISC\n",
            "      8  title         O\n",
            "      9  with          O\n",
            "     10  a             O\n",
            "     11  lucky         O\n",
            "     12  2-1           O\n",
            "     13  win           O\n",
            "     14  against       O\n",
            "     15  Syria         B-LOC\n",
            "     16  in            O\n",
            "     17  a             O\n",
            "     18  Group         O\n",
            "     19  C             O\n",
            "     20  championship  O\n",
            "     21  match         O\n",
            "     22  on            O\n",
            "     23  Friday        O\n",
            "     24  .             O\n",
            "\n",
            "True Entities: [('LOC', 'Japan'), ('MISC', 'Asian Cup'), ('LOC', 'Syria')]\n",
            "Predicted Entities: [('LOC', 'Japan'), ('MISC', 'Asian Cup'), ('LOC', 'Syria')]\n",
            "--------------------------------------------------------------------------------\n",
            "Example 5:\n",
            "Sentence: But China saw their luck desert them in the second match of the group , crashing to a surprise 2-0 defeat to newcomers Uzbekistan .\n",
            "\n",
            "  Index  Token       True Label\n",
            "-------  ----------  ------------\n",
            "      0  But         O\n",
            "      1  China       B-LOC\n",
            "      2  saw         O\n",
            "      3  their       O\n",
            "      4  luck        O\n",
            "      5  desert      O\n",
            "      6  them        O\n",
            "      7  in          O\n",
            "      8  the         O\n",
            "      9  second      O\n",
            "     10  match       O\n",
            "     11  of          O\n",
            "     12  the         O\n",
            "     13  group       O\n",
            "     14  ,           O\n",
            "     15  crashing    O\n",
            "     16  to          O\n",
            "     17  a           O\n",
            "     18  surprise    O\n",
            "     19  2-0         O\n",
            "     20  defeat      O\n",
            "     21  to          O\n",
            "     22  newcomers   O\n",
            "     23  Uzbekistan  B-LOC\n",
            "     24  .           O\n",
            "\n",
            "True Entities: [('LOC', 'China'), ('LOC', 'Uzbekistan')]\n",
            "Predicted Entities: [('LOC', 'China'), ('ORG', 'Uzbekistan')]\n",
            "Token 'Uzbekistan' - True: B-LOC, Predicted: B-ORG\n",
            "Top contributing features (predicted value contribution, true value contribution):\n",
            "--------------------------------------------------------------------------------\n",
            "Example 6:\n",
            "Sentence: China controlled most of the match and saw several chances missed until the 78th minute when Uzbek striker Igor Shkvyrin took advantage of a misdirected defensive header to lob the ball over the advancing Chinese keeper and into an empty net .\n",
            "\n",
            "  Index  Token        True Label\n",
            "-------  -----------  ------------\n",
            "      0  China        B-LOC\n",
            "      1  controlled   O\n",
            "      2  most         O\n",
            "      3  of           O\n",
            "      4  the          O\n",
            "      5  match        O\n",
            "      6  and          O\n",
            "      7  saw          O\n",
            "      8  several      O\n",
            "      9  chances      O\n",
            "     10  missed       O\n",
            "     11  until        O\n",
            "     12  the          O\n",
            "     13  78th         O\n",
            "     14  minute       O\n",
            "     15  when         O\n",
            "     16  Uzbek        B-MISC\n",
            "     17  striker      O\n",
            "     18  Igor         B-PER\n",
            "     19  Shkvyrin     I-PER\n",
            "     20  took         O\n",
            "     21  advantage    O\n",
            "     22  of           O\n",
            "     23  a            O\n",
            "     24  misdirected  O\n",
            "     25  defensive    O\n",
            "     26  header       O\n",
            "     27  to           O\n",
            "     28  lob          O\n",
            "     29  the          O\n",
            "     30  ball         O\n",
            "     31  over         O\n",
            "     32  the          O\n",
            "     33  advancing    O\n",
            "     34  Chinese      B-MISC\n",
            "     35  keeper       O\n",
            "     36  and          O\n",
            "     37  into         O\n",
            "     38  an           O\n",
            "     39  empty        O\n",
            "     40  net          O\n",
            "     41  .            O\n",
            "\n",
            "True Entities: [('LOC', 'China'), ('MISC', 'Uzbek'), ('PER', 'Igor Shkvyrin'), ('MISC', 'Chinese')]\n",
            "Predicted Entities: [('LOC', 'China'), ('ORG', 'Uzbek'), ('PER', 'Igor Shkvyrin'), ('MISC', 'Chinese')]\n",
            "Token 'Uzbek' - True: B-MISC, Predicted: B-ORG\n",
            "Top contributing features (predicted value contribution, true value contribution):\n",
            "--------------------------------------------------------------------------------\n",
            "Example 7:\n",
            "Sentence: Oleg Shatskiku made sure of the win in injury time , hitting an unstoppable left foot shot from just outside the area .\n",
            "\n",
            "  Index  Token        True Label\n",
            "-------  -----------  ------------\n",
            "      0  Oleg         B-PER\n",
            "      1  Shatskiku    I-PER\n",
            "      2  made         O\n",
            "      3  sure         O\n",
            "      4  of           O\n",
            "      5  the          O\n",
            "      6  win          O\n",
            "      7  in           O\n",
            "      8  injury       O\n",
            "      9  time         O\n",
            "     10  ,            O\n",
            "     11  hitting      O\n",
            "     12  an           O\n",
            "     13  unstoppable  O\n",
            "     14  left         O\n",
            "     15  foot         O\n",
            "     16  shot         O\n",
            "     17  from         O\n",
            "     18  just         O\n",
            "     19  outside      O\n",
            "     20  the          O\n",
            "     21  area         O\n",
            "     22  .            O\n",
            "\n",
            "True Entities: [('PER', 'Oleg Shatskiku')]\n",
            "Predicted Entities: [('PER', 'Oleg Shatskiku')]\n",
            "--------------------------------------------------------------------------------\n",
            "Example 8:\n",
            "Sentence: The former Soviet republic was playing in an Asian Cup finals tie for the first time .\n",
            "\n",
            "  Index  Token     True Label\n",
            "-------  --------  ------------\n",
            "      0  The       O\n",
            "      1  former    O\n",
            "      2  Soviet    B-MISC\n",
            "      3  republic  O\n",
            "      4  was       O\n",
            "      5  playing   O\n",
            "      6  in        O\n",
            "      7  an        O\n",
            "      8  Asian     B-MISC\n",
            "      9  Cup       I-MISC\n",
            "     10  finals    O\n",
            "     11  tie       O\n",
            "     12  for       O\n",
            "     13  the       O\n",
            "     14  first     O\n",
            "     15  time      O\n",
            "     16  .         O\n",
            "\n",
            "True Entities: [('MISC', 'Soviet'), ('MISC', 'Asian Cup')]\n",
            "Predicted Entities: [('MISC', 'Soviet'), ('MISC', 'Asian Cup')]\n",
            "--------------------------------------------------------------------------------\n",
            "Example 9:\n",
            "Sentence: Despite winning the Asian Games title two years ago , Uzbekistan are in the finals as outsiders .\n",
            "\n",
            "  Index  Token       True Label\n",
            "-------  ----------  ------------\n",
            "      0  Despite     O\n",
            "      1  winning     O\n",
            "      2  the         O\n",
            "      3  Asian       B-MISC\n",
            "      4  Games       I-MISC\n",
            "      5  title       O\n",
            "      6  two         O\n",
            "      7  years       O\n",
            "      8  ago         O\n",
            "      9  ,           O\n",
            "     10  Uzbekistan  B-LOC\n",
            "     11  are         O\n",
            "     12  in          O\n",
            "     13  the         O\n",
            "     14  finals      O\n",
            "     15  as          O\n",
            "     16  outsiders   O\n",
            "     17  .           O\n",
            "\n",
            "True Entities: [('MISC', 'Asian Games'), ('LOC', 'Uzbekistan')]\n",
            "Predicted Entities: [('MISC', 'Asian Games'), ('LOC', 'Uzbekistan')]\n",
            "--------------------------------------------------------------------------------\n",
            "Example 10:\n",
            "Sentence: Two goals from defensive errors in the last six minutes allowed Japan to come from behind and collect all three points from their opening meeting against Syria .\n",
            "\n",
            "  Index  Token      True Label\n",
            "-------  ---------  ------------\n",
            "      0  Two        O\n",
            "      1  goals      O\n",
            "      2  from       O\n",
            "      3  defensive  O\n",
            "      4  errors     O\n",
            "      5  in         O\n",
            "      6  the        O\n",
            "      7  last       O\n",
            "      8  six        O\n",
            "      9  minutes    O\n",
            "     10  allowed    O\n",
            "     11  Japan      B-LOC\n",
            "     12  to         O\n",
            "     13  come       O\n",
            "     14  from       O\n",
            "     15  behind     O\n",
            "     16  and        O\n",
            "     17  collect    O\n",
            "     18  all        O\n",
            "     19  three      O\n",
            "     20  points     O\n",
            "     21  from       O\n",
            "     22  their      O\n",
            "     23  opening    O\n",
            "     24  meeting    O\n",
            "     25  against    O\n",
            "     26  Syria      B-LOC\n",
            "     27  .          O\n",
            "\n",
            "True Entities: [('LOC', 'Japan'), ('LOC', 'Syria')]\n",
            "Predicted Entities: [('LOC', 'Japan'), ('LOC', 'Syria')]\n",
            "--------------------------------------------------------------------------------\n",
            "Detailed Error Pattern Analysis:\n",
            "--------------------------------------------------------------------------------\n",
            "Total tokens analyzed: 46435\n",
            "Total errors: 1777\n",
            "Error rate: 3.83%\n",
            "\n",
            "Error patterns:\n",
            "  O_as_entity: 423 (23.8% of errors)\n",
            "  entity_as_O: 359 (20.2% of errors)\n",
            "  ORG_as_LOC: 145 (8.2% of errors)\n",
            "  LOC_as_ORG: 108 (6.1% of errors)\n",
            "  boundary_errors: 97 (5.5% of errors)\n",
            "  LOC_as_PER: 71 (4.0% of errors)\n",
            "  ORG_as_MISC: 65 (3.7% of errors)\n",
            "  MISC_as_ORG: 61 (3.4% of errors)\n",
            "  PER_as_LOC: 43 (2.4% of errors)\n",
            "Analyzing Prediction Confidence:\n",
            "--------------------------------------------------------------------------------\n",
            "Example 1:\n",
            "  Position  Predicted      Confidence  Top 3 Labels\n",
            "----------  -----------  ------------  -----------------------------------------\n",
            "         0  O                0.980685  O(0.981), B-PER(0.010), B-LOC(0.007)\n",
            "         1  O                0.999997  O(1.000), B-MISC(0.000), B-PER(0.000)\n",
            "         2  B-PER            0.400844  B-PER(0.401), B-LOC(0.224), B-MISC(0.198)\n",
            "         3  O                0.914999  O(0.915), I-ORG(0.035), I-MISC(0.029)\n",
            "         4  O                0.830707  O(0.831), B-ORG(0.088), B-MISC(0.023)\n",
            "         5  O                0.986577  O(0.987), I-ORG(0.007), B-LOC(0.002)\n",
            "         6  O                0.999998  O(1.000), I-MISC(0.000), B-MISC(0.000)\n",
            "         7  B-LOC            0.624984  B-LOC(0.625), B-ORG(0.342), B-PER(0.020)\n",
            "         8  O                0.980997  O(0.981), I-ORG(0.010), I-LOC(0.007)\n",
            "         9  O                0.863381  O(0.863), B-MISC(0.103), B-LOC(0.019)\n",
            "        10  O                0.946004  O(0.946), I-MISC(0.036), I-ORG(0.005)\n",
            "        11  O                0.999938  O(1.000), I-MISC(0.000), I-ORG(0.000)\n",
            "--------------------------------------------------------------------------------\n",
            "Example 2:\n",
            "  Position  Predicted      Confidence  Top 3 Labels\n",
            "----------  -----------  ------------  -----------------------------------------\n",
            "         0  B-PER            0.999163  B-PER(0.999), B-LOC(0.000), B-MISC(0.000)\n",
            "         1  I-PER            0.999147  I-PER(0.999), I-LOC(0.000), I-MISC(0.000)\n",
            "--------------------------------------------------------------------------------\n",
            "Example 3:\n",
            "  Position  Predicted      Confidence  Top 3 Labels\n",
            "----------  -----------  ------------  -----------------------------------------\n",
            "         0  B-LOC            0.782497  B-LOC(0.782), O(0.113), B-ORG(0.071)\n",
            "         1  O                0.999952  O(1.000), I-LOC(0.000), I-ORG(0.000)\n",
            "         2  B-LOC            0.981696  B-LOC(0.982), B-ORG(0.014), B-PER(0.003)\n",
            "         3  I-LOC            0.985263  I-LOC(0.985), B-MISC(0.006), I-ORG(0.005)\n",
            "         4  I-LOC            0.986007  I-LOC(0.986), I-MISC(0.005), I-ORG(0.004)\n",
            "         5  O                0.999281  O(0.999), I-LOC(0.001), B-MISC(0.000)\n",
            "--------------------------------------------------------------------------------\n",
            "Example 4:\n",
            "  Position  Predicted      Confidence  Top 3 Labels\n",
            "----------  -----------  ------------  -----------------------------------------\n",
            "         0  B-LOC            0.938508  B-LOC(0.939), O(0.021), B-PER(0.021)\n",
            "         1  O                0.999703  O(1.000), I-LOC(0.000), I-PER(0.000)\n",
            "         2  O                0.999981  O(1.000), I-LOC(0.000), B-ORG(0.000)\n",
            "         3  O                0.999877  O(1.000), B-ORG(0.000), B-LOC(0.000)\n",
            "         4  O                0.999878  O(1.000), B-ORG(0.000), I-ORG(0.000)\n",
            "         5  O                0.99965   O(1.000), B-MISC(0.000), B-LOC(0.000)\n",
            "         6  B-MISC           0.99993   B-MISC(1.000), B-PER(0.000), B-ORG(0.000)\n",
            "         7  I-MISC           0.992656  I-MISC(0.993), B-MISC(0.006), O(0.001)\n",
            "         8  O                0.994299  O(0.994), I-MISC(0.005), B-ORG(0.001)\n",
            "         9  O                0.999989  O(1.000), I-MISC(0.000), B-ORG(0.000)\n",
            "        10  O                0.999909  O(1.000), B-PER(0.000), B-ORG(0.000)\n",
            "        11  O                0.997436  O(0.997), B-ORG(0.002), B-MISC(0.001)\n",
            "        12  O                0.999802  O(1.000), B-MISC(0.000), B-ORG(0.000)\n",
            "        13  O                0.999978  O(1.000), B-LOC(0.000), B-PER(0.000)\n",
            "        14  O                0.999917  O(1.000), B-LOC(0.000), B-ORG(0.000)\n",
            "        15  B-LOC            0.931606  B-LOC(0.932), B-ORG(0.058), B-PER(0.007)\n",
            "        16  O                0.999892  O(1.000), I-ORG(0.000), I-LOC(0.000)\n",
            "        17  O                0.999971  O(1.000), B-LOC(0.000), B-ORG(0.000)\n",
            "        18  O                0.951592  O(0.952), B-MISC(0.041), B-LOC(0.003)\n",
            "        19  O                0.95852   O(0.959), B-ORG(0.023), I-MISC(0.016)\n",
            "        20  O                0.995796  O(0.996), I-MISC(0.004), I-ORG(0.000)\n",
            "        21  O                0.999995  O(1.000), B-ORG(0.000), B-LOC(0.000)\n",
            "        22  O                0.999993  O(1.000), B-ORG(0.000), B-LOC(0.000)\n",
            "        23  O                0.999002  O(0.999), B-ORG(0.000), B-LOC(0.000)\n",
            "        24  O                0.999978  O(1.000), I-ORG(0.000), I-LOC(0.000)\n",
            "--------------------------------------------------------------------------------\n",
            "Example 5:\n",
            "  Position  Predicted      Confidence  Top 3 Labels\n",
            "----------  -----------  ------------  -----------------------------------------\n",
            "         0  O                0.999338  O(0.999), B-PER(0.000), B-ORG(0.000)\n",
            "         1  B-LOC            0.987926  B-LOC(0.988), B-PER(0.009), B-ORG(0.002)\n",
            "         2  O                0.999791  O(1.000), I-LOC(0.000), I-PER(0.000)\n",
            "         3  O                0.999921  O(1.000), B-PER(0.000), B-ORG(0.000)\n",
            "         4  O                0.99961   O(1.000), B-PER(0.000), B-LOC(0.000)\n",
            "         5  O                0.999429  O(0.999), B-PER(0.000), B-ORG(0.000)\n",
            "         6  O                0.999876  O(1.000), I-PER(0.000), B-LOC(0.000)\n",
            "         7  O                0.999999  O(1.000), B-PER(0.000), B-LOC(0.000)\n",
            "         8  O                0.999994  O(1.000), I-ORG(0.000), B-LOC(0.000)\n",
            "         9  O                0.999959  O(1.000), B-MISC(0.000), B-ORG(0.000)\n",
            "        10  O                0.999999  O(1.000), B-MISC(0.000), B-ORG(0.000)\n",
            "        11  O                0.999972  O(1.000), B-MISC(0.000), B-ORG(0.000)\n",
            "        12  O                0.999894  O(1.000), I-LOC(0.000), I-MISC(0.000)\n",
            "        13  O                0.999978  O(1.000), B-LOC(0.000), B-MISC(0.000)\n",
            "        14  O                0.999941  O(1.000), B-ORG(0.000), B-MISC(0.000)\n",
            "        15  O                0.999979  O(1.000), B-PER(0.000), B-ORG(0.000)\n",
            "        16  O                0.999987  O(1.000), B-PER(0.000), B-LOC(0.000)\n",
            "        17  O                0.999952  O(1.000), B-ORG(0.000), B-LOC(0.000)\n",
            "        18  O                0.999701  O(1.000), B-MISC(0.000), B-ORG(0.000)\n",
            "        19  O                0.999958  O(1.000), B-MISC(0.000), B-ORG(0.000)\n",
            "        20  O                0.999958  O(1.000), B-ORG(0.000), B-LOC(0.000)\n",
            "        21  O                0.999996  O(1.000), B-LOC(0.000), B-MISC(0.000)\n",
            "        22  O                0.999992  O(1.000), B-ORG(0.000), B-MISC(0.000)\n",
            "        23  B-ORG            0.532567  B-ORG(0.533), B-LOC(0.442), B-MISC(0.015)\n",
            "        24  O                0.996253  O(0.996), I-ORG(0.003), I-LOC(0.001)\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}
