{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaHJfcQHkRzxEfebw7WcHQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shriyatha/Named_Entity_Recognition/blob/main/RULE_BASED_NER_Telugu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets evaluate seqeval spacy tabulate -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aECJcTLZDNfa",
        "outputId": "0ca73862-d857-4ac0-8d60-ad4d096a32a7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VCwd6z90DBLh"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
        "import spacy\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "from tabulate import tabulate\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from seqeval.scheme import IOB2 as IOB2Scheme"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TeluguNER:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the Telugu NER system with multilingual spaCy model and Telugu-specific patterns\"\"\"\n",
        "        # Load spaCy's multilingual model\n",
        "        try:\n",
        "            self.nlp = spacy.load(\"xx_ent_wiki_sm\")\n",
        "        except:\n",
        "            print(\"Installing spaCy multilingual model...\")\n",
        "            spacy.cli.download(\"xx_ent_wiki_sm\")\n",
        "            self.nlp = spacy.load(\"xx_ent_wiki_sm\")\n",
        "\n",
        "        # Entity configuration\n",
        "        self.allowed_entities = {\"PER\", \"LOC\", \"ORG\"}\n",
        "        self.spacy_to_wiki = {\n",
        "            \"PERSON\": \"PER\",\n",
        "            \"GPE\": \"LOC\",\n",
        "            \"LOC\": \"LOC\",\n",
        "            \"ORG\": \"ORG\",\n",
        "            \"NORP\": \"ORG\",\n",
        "            \"FAC\": \"LOC\"\n",
        "        }\n",
        "\n",
        "        # Initialize pattern stores and statistical trackers\n",
        "        self._initialize_patterns()\n",
        "        self._initialize_trackers()\n",
        "\n",
        "    def _initialize_patterns(self):\n",
        "        \"\"\"Initialize Telugu-specific patterns for different entity types\"\"\"\n",
        "        # Name patterns for person entities\n",
        "        self.correction_patterns = {\n",
        "            \"PER\": {\n",
        "                \"name_patterns\": [\n",
        "                    re.compile(r'.*(?:రెడ్డి|శర్మ|వర్మ|నాయుడు|చౌదరి|రావు|కుమార్|దేవి|గౌడ్|జోషి|పాటేల్|మీనా)$'),\n",
        "                    re.compile(r'^(?:శ్రీ|శ్రీమతి|శ్రీమాన్|డాక్టర్|ప్రొఫెసర్) .*')\n",
        "                ],\n",
        "                \"full_name_patterns\": [\n",
        "                    re.compile(r'^[^\\s]+\\s+[^\\s]+(?:\\s+[^\\s]+)?$') # Fixed: Added closing parenthesis and $\n",
        "                ]\n",
        "            },\n",
        "            \"ORG\": {\n",
        "                \"company_patterns\": [\n",
        "                    re.compile(r'.*(?:లిమిటెడ్|ప్రైవేట్|కంపెనీ|సంస్థ|బ్యాంక్)$'), # Fixed: Added closing parenthesis and $\n",
        "                ],\n",
        "                \"educational_patterns\": [\n",
        "                    re.compile(r'^(?:విశ్వవిద్యాలయం|కళాశాల|పాఠశాల|ఇన్స్టిట్యూట్).*$'), # Fixed: Added closing parenthesis and $\n",
        "                    re.compile(r'.*(?:విశ్వవిద్యాలయం|కళాశాల|పాఠశాల|ఇన్స్టిట్యూట్)$') # Fixed: Added closing parenthesis and $\n",
        "                ]\n",
        "            },\n",
        "            \"LOC\": {\n",
        "                \"geographic_patterns\": [\n",
        "                    re.compile(r'.*(?:జిల్లా|నగరం|గ్రామం|రాష్ట్రం|దేశం|మండలం|కేంద్రం|నగర్)$'), # Fixed: Added closing parenthesis and $\n",
        "                ],\n",
        "                \"natural_features\": [\n",
        "                    re.compile(r'.*(?:నది|పర్వతం|సముద్రం|సరస్సు|దక్షిణ|ఉత్తర|పశ్చిమ|తూర్పు)$') # Fixed: Added closing parenthesis and $\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # High-precision patterns\n",
        "        self.high_precision_patterns = {\n",
        "            \"PER\": [\n",
        "                re.compile(r'.*(?:గారు|జీ)$'), # Fixed: Added closing parenthesis and $\n",
        "                re.compile(r'^(?:డాక్టర్|ప్రొఫెసర్|నేతాజీ) .*')\n",
        "            ],\n",
        "            \"ORG\": [\n",
        "                re.compile(r'.*(?:కార్పొరేషన్|సంఘం|మండలి|పరిషత్)$'), # Fixed: Added closing parenthesis and $\n",
        "                re.compile(r'^(?:భారత|ఆంధ్రప్రదేశ్|తెలంగాణ) .*(?:ప్రభుత్వం|సంస్థ)$') # Fixed: Added closing parenthesis and $\n",
        "            ],\n",
        "            \"LOC\": [\n",
        "                re.compile(r'.*(?:రాష్ట్రం|దేశం|రాజధాని|ప్రాంతం)$'), # Fixed: Added closing parenthesis and $\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # Context indicators\n",
        "        self.context_indicators = {\n",
        "            \"PER\": [\"అయిన\", \"పేరు\", \"వ్యక్తి\", \"నటుడు\", \"నటి\", \"రచయిత\", \"కుమారుడు\", \"కుమార్తె\", \"అన్న\", \"అక్క\"],\n",
        "            \"ORG\": [\"సంస్థ\", \"కంపెనీ\", \"బృందం\", \"సమూహం\", \"పార్టీ\", \"ఆఫీసు\", \"శాఖ\", \"యూనిట్\"],\n",
        "            \"LOC\": [\"ప్రాంతం\", \"నగరం\", \"దేశం\", \"రాష్ట్రం\", \"గ్రామం\"]\n",
        "        }\n",
        "\n",
        "        self.context_post_indicators = {\n",
        "            \"PER\": [\"చెప్పారు\", \"తెలిపారు\", \"అన్నారు\", \"పేర్కొన్నారు\"],\n",
        "            \"ORG\": [\"ప్రకటించింది\", \"తెలిపింది\", \"నిర్వహించింది\"],\n",
        "            \"LOC\": [\"లో\", \"నుండి\", \"వరకు\", \"లోని\", \"ప్రాంతంలో\"]\n",
        "        }\n",
        "    def _initialize_trackers(self):\n",
        "        \"\"\"Initialize statistical trackers and performance metrics\"\"\"\n",
        "        self.misclassification_corrections = defaultdict(list)\n",
        "        self.confusion_matrix = {\n",
        "            \"PER\": {\"PER\": 0, \"LOC\": 0, \"ORG\": 0, \"O\": 0},\n",
        "            \"LOC\": {\"PER\": 0, \"LOC\": 0, \"ORG\": 0, \"O\": 0},\n",
        "            \"ORG\": {\"PER\": 0, \"LOC\": 0, \"ORG\": 0, \"O\": 0},\n",
        "            \"O\": {\"PER\": 0, \"LOC\": 0, \"ORG\": 0, \"O\": 0}\n",
        "        }\n",
        "        self.performance_metrics = {}\n",
        "        self.error_examples = []\n",
        "        self.entity_token_freq = {\n",
        "            \"PER\": Counter(),\n",
        "            \"LOC\": Counter(),\n",
        "            \"ORG\": Counter()\n",
        "        }\n",
        "        self.token_confidence = {}\n",
        "        self.entity_errors = defaultdict(lambda: {\"missed\": 0, \"wrong_type\": 0, \"partial\": 0})\n",
        "\n",
        "    def find_token_span(self, tokens, text):\n",
        "        \"\"\"Find token span in a list of tokens by matching words.\n",
        "        This is more robust than exact matching.\"\"\"\n",
        "        target_tokens = text.split()\n",
        "\n",
        "        if not target_tokens:\n",
        "            return None\n",
        "\n",
        "        for i in range(len(tokens) - len(target_tokens) + 1):\n",
        "            match = True\n",
        "            for j, target_token in enumerate(target_tokens):\n",
        "                if tokens[i+j].lower() != target_token.lower():\n",
        "                    match = False\n",
        "                    break\n",
        "            if match:\n",
        "                return i, i + len(target_tokens)\n",
        "        return None\n",
        "\n",
        "    def create_balanced_dataset(self, dataset_split=\"train\", max_samples_per_class=2000, min_samples_per_class=500):\n",
        "        \"\"\"Create a balanced dataset by downsampling majority classes\"\"\"\n",
        "        print(f\"Creating balanced dataset from {dataset_split} split...\")\n",
        "\n",
        "        split_data = dataset[dataset_split]\n",
        "        id_to_label = split_data.features[\"ner_tags\"].feature.int2str\n",
        "\n",
        "        # Count entity types\n",
        "        entity_examples = defaultdict(list)\n",
        "        other_examples = []\n",
        "\n",
        "        for idx, (tokens, tags) in enumerate(zip(split_data[\"tokens\"], split_data[\"ner_tags\"])):\n",
        "            string_tags = [id_to_label(tag) for tag in tags]\n",
        "            entity_types_in_example = set()\n",
        "\n",
        "            for tag in string_tags:\n",
        "                if tag != \"O\":\n",
        "                    entity_type = tag[2:] if \"-\" in tag else tag\n",
        "                    entity_types_in_example.add(entity_type)\n",
        "\n",
        "            if entity_types_in_example:\n",
        "                for entity_type in entity_types_in_example:\n",
        "                    entity_examples[entity_type].append(idx)\n",
        "            else:\n",
        "                other_examples.append(idx)\n",
        "\n",
        "        # Print entity distribution\n",
        "        print(\"Entity distribution in original dataset:\")\n",
        "        for entity_type, examples in entity_examples.items():\n",
        "            print(f\"  {entity_type}: {len(examples)} examples\")\n",
        "        print(f\"  None (O): {len(other_examples)} examples\")\n",
        "\n",
        "        # Select balanced samples\n",
        "        selected_indices = []\n",
        "        for entity_type, examples in entity_examples.items():\n",
        "            num_samples = min(max_samples_per_class, len(examples))\n",
        "            num_samples = max(num_samples, min_samples_per_class)\n",
        "            selected_indices.extend(random.sample(examples, num_samples))\n",
        "\n",
        "        # Add proportional \"O\" examples\n",
        "        num_other_samples = min(len(selected_indices) // 2, len(other_examples))\n",
        "        selected_indices.extend(random.sample(other_examples, num_other_samples))\n",
        "\n",
        "        return {\n",
        "            \"tokens\": [split_data[\"tokens\"][i] for i in selected_indices],\n",
        "            \"ner_tags\": [split_data[\"ner_tags\"][i] for i in selected_indices]\n",
        "        }\n",
        "\n",
        "    def load_correction_patterns_from_training(self, dataset_data):\n",
        "        \"\"\"Learn common misclassifications from training data\"\"\"\n",
        "        print(\"Learning correction patterns from training data...\")\n",
        "        id_to_label = dataset_data[\"train\"].features[\"ner_tags\"].feature.int2str\n",
        "\n",
        "        spacy_errors = defaultdict(Counter)\n",
        "        entity_stats = defaultdict(int)\n",
        "        entity_tokens = defaultdict(Counter)\n",
        "        train_data = dataset_data[\"train\"]\n",
        "\n",
        "        for idx, (tokens, tags) in enumerate(tqdm(zip(train_data[\"tokens\"], train_data[\"ner_tags\"]),\n",
        "                                             total=len(train_data[\"tokens\"]), desc=\"Analyzing training data\")):\n",
        "            string_tags = [id_to_label(tag) for tag in tags]\n",
        "            text = \" \".join(tokens)\n",
        "            doc = self.nlp(text)\n",
        "\n",
        "            # Track entity statistics and token frequencies\n",
        "            i = 0\n",
        "            while i < len(tokens):\n",
        "                tag = string_tags[i]\n",
        "                if tag.startswith(\"B-\"):\n",
        "                    entity_type = tag[2:]\n",
        "                    entity_stats[entity_type] += 1\n",
        "                    entity_tokens[entity_type][tokens[i]] += 1\n",
        "\n",
        "                    j = i + 1\n",
        "                    while j < len(string_tags) and string_tags[j].startswith(\"I-\") and string_tags[j][2:] == entity_type:\n",
        "                        entity_tokens[entity_type][tokens[j]] += 1\n",
        "                        j += 1\n",
        "                    i = j\n",
        "                else:\n",
        "                    i += 1\n",
        "\n",
        "            # Extract entities from spaCy\n",
        "            spacy_entities = []\n",
        "            for ent in doc.ents:\n",
        "                if ent.label_ in self.spacy_to_wiki:\n",
        "                    wiki_label = self.spacy_to_wiki[ent.label_]\n",
        "                    spacy_entities.append((ent.text, wiki_label, ent.start_char, ent.end_char))\n",
        "\n",
        "            # Extract gold entities\n",
        "            gold_entities = []\n",
        "            i = 0\n",
        "            while i < len(tokens):\n",
        "                if string_tags[i].startswith(\"B-\"):\n",
        "                    entity_type = string_tags[i][2:]\n",
        "                    start_idx = i\n",
        "                    i += 1\n",
        "                    while i < len(string_tags) and string_tags[i].startswith(\"I-\") and string_tags[i][2:] == entity_type:\n",
        "                        i += 1\n",
        "                    end_idx = i\n",
        "                    entity_text = \" \".join(tokens[start_idx:end_idx])\n",
        "                    gold_entities.append((entity_text, entity_type))\n",
        "                else:\n",
        "                    i += 1\n",
        "\n",
        "            # Find missed entities\n",
        "            for gold_text, gold_type in gold_entities:\n",
        "                found = False\n",
        "                for spacy_text, spacy_type, _, _ in spacy_entities:\n",
        "                    if gold_text.lower() == spacy_text.lower():\n",
        "                        found = True\n",
        "                        break\n",
        "\n",
        "                if not found:\n",
        "                    spacy_errors[gold_type][gold_text] += 1\n",
        "\n",
        "        print(f\"Entity statistics in training data: {dict(entity_stats)}\")\n",
        "        self.entity_token_freq = entity_tokens\n",
        "        self._calculate_token_confidence_scores()\n",
        "\n",
        "        # Create correction patterns\n",
        "        pattern_count = 0\n",
        "        for entity_type, error_counter in spacy_errors.items():\n",
        "            for phrase, count in error_counter.most_common(100):\n",
        "                if count > 1 and len(phrase) > 2:\n",
        "                    try:\n",
        "                        # Use word boundary for more precise matching\n",
        "                        escaped_phrase = re.escape(phrase)\n",
        "                        pattern = re.compile(r'\\b' + escaped_phrase + r'\\b')\n",
        "                        self.misclassification_corrections[entity_type].append((pattern, count))\n",
        "                        pattern_count += 1\n",
        "                    except re.error:\n",
        "                        continue\n",
        "\n",
        "        print(f\"Created {pattern_count} correction patterns from training data\")\n",
        "\n",
        "    def _calculate_token_confidence_scores(self):\n",
        "        \"\"\"Calculate confidence scores for tokens based on their frequency in different entity types\"\"\"\n",
        "        all_tokens = Counter()\n",
        "        for entity_type, counter in self.entity_token_freq.items():\n",
        "            for token, count in counter.items():\n",
        "                all_tokens[token] += count\n",
        "\n",
        "        # Only consider tokens that appear multiple times\n",
        "        for token, total_count in all_tokens.items():\n",
        "            if total_count < 3:  # Require at least 3 occurrences\n",
        "                continue\n",
        "\n",
        "            scores = {}\n",
        "            for entity_type in self.allowed_entities:\n",
        "                entity_count = self.entity_token_freq[entity_type].get(token, 0)\n",
        "                if entity_count > 0:\n",
        "                    scores[entity_type] = entity_count / total_count\n",
        "\n",
        "            if scores:\n",
        "                max_type = max(scores, key=scores.get)\n",
        "                # Only keep tokens with strong entity association\n",
        "                if scores[max_type] > 0.7:  # Increased threshold for higher precision\n",
        "                    self.token_confidence[token] = (max_type, scores[max_type])\n",
        "\n",
        "    def get_spacy_predictions(self, tokens):\n",
        "        \"\"\"Get entity predictions from spaCy model\"\"\"\n",
        "        text = \" \".join(tokens)\n",
        "        doc = self.nlp(text)\n",
        "\n",
        "        labels = [\"O\"] * len(tokens)\n",
        "        confidence = [0.0] * len(tokens)\n",
        "\n",
        "        # Create a mapping from character positions to token indices\n",
        "        char_to_token = {}\n",
        "        char_pos = 0\n",
        "        for i, token in enumerate(tokens):\n",
        "            for j in range(len(token)):\n",
        "                char_to_token[char_pos + j] = i\n",
        "            char_pos += len(token) + 1  # +1 for space\n",
        "\n",
        "        # Apply spaCy entities\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ in self.spacy_to_wiki:\n",
        "                entity_type = self.spacy_to_wiki[ent.label_]\n",
        "                if entity_type in self.allowed_entities:\n",
        "                    # Find token spans using character positions\n",
        "                    try:\n",
        "                        start_token = char_to_token.get(ent.start_char, None)\n",
        "                        end_token = char_to_token.get(ent.end_char - 1, None)\n",
        "\n",
        "                        if start_token is not None and end_token is not None:\n",
        "                            labels[start_token] = f\"B-{entity_type}\"\n",
        "                            confidence[start_token] = 0.7\n",
        "\n",
        "                            for i in range(start_token + 1, end_token + 1):\n",
        "                                if i < len(tokens):\n",
        "                                    labels[i] = f\"I-{entity_type}\"\n",
        "                                    confidence[i] = 0.7\n",
        "                    except:\n",
        "                        # Fall back to text matching if character positions fail\n",
        "                        span = self.find_token_span(tokens, ent.text)\n",
        "                        if span:\n",
        "                            start, end = span\n",
        "                            labels[start] = f\"B-{entity_type}\"\n",
        "                            confidence[start] = 0.7\n",
        "                            for i in range(start + 1, end):\n",
        "                                labels[i] = f\"I-{entity_type}\"\n",
        "                                confidence[i] = 0.7\n",
        "\n",
        "        return labels, confidence\n",
        "\n",
        "    def apply_regex_patterns(self, tokens):\n",
        "        \"\"\"Apply regex pattern-based entity detection with confidence scoring\"\"\"\n",
        "        regex_labels = [\"O\"] * len(tokens)\n",
        "        confidence_scores = [0.0] * len(tokens)\n",
        "        text = \" \".join(tokens)\n",
        "\n",
        "        # Apply high precision patterns first\n",
        "        for entity_type, patterns in self.high_precision_patterns.items():\n",
        "            for pattern in patterns:\n",
        "                # Check full text for matches\n",
        "                try:\n",
        "                    for match in pattern.finditer(text):\n",
        "                        matched_text = match.group()\n",
        "                        span = self.find_token_span(tokens, matched_text)\n",
        "                        if span:\n",
        "                            start, end = span\n",
        "                            regex_labels[start] = f\"B-{entity_type}\"\n",
        "                            confidence_scores[start] = 0.95\n",
        "                            for i in range(start + 1, end):\n",
        "                                regex_labels[i] = f\"I-{entity_type}\"\n",
        "                                confidence_scores[i] = 0.95\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        # Apply regular patterns with lower confidence\n",
        "        for entity_type, pattern_groups in self.correction_patterns.items():\n",
        "            for group_name, patterns in pattern_groups.items():\n",
        "                base_confidence = 0.85\n",
        "                if \"name_patterns\" in group_name or \"full_name_patterns\" in group_name:\n",
        "                    base_confidence = 0.9\n",
        "\n",
        "                for pattern in patterns:\n",
        "                    try:\n",
        "                        for match in pattern.finditer(text):\n",
        "                            matched_text = match.group()\n",
        "                            span = self.find_token_span(tokens, matched_text)\n",
        "                            if span and all(regex_labels[i] == \"O\" for i in range(span[0], span[1])):\n",
        "                                start, end = span\n",
        "                                regex_labels[start] = f\"B-{entity_type}\"\n",
        "                                confidence_scores[start] = base_confidence\n",
        "                                for i in range(start + 1, end):\n",
        "                                    regex_labels[i] = f\"I-{entity_type}\"\n",
        "                                    confidence_scores[i] = base_confidence\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "        return regex_labels, confidence_scores\n",
        "\n",
        "    def check_context_indicators(self, tokens):\n",
        "        \"\"\"Use context words to identify potential entities\"\"\"\n",
        "        context_labels = [\"O\"] * len(tokens)\n",
        "        confidence_scores = [0.0] * len(tokens)\n",
        "\n",
        "        # Forward context indicators\n",
        "        for i, token in enumerate(tokens):\n",
        "            if i < len(tokens) - 1:  # Make sure we're not at the last token\n",
        "                for entity_type, indicators in self.context_indicators.items():\n",
        "                    if token.lower() in indicators:\n",
        "                        # The token after the indicator is likely the start of the entity\n",
        "                        if i+1 < len(tokens):\n",
        "                            context_labels[i+1] = f\"B-{entity_type}\"\n",
        "                            confidence_scores[i+1] = 0.7\n",
        "\n",
        "                            # Look for continuation of the entity (up to 3 tokens)\n",
        "                            for j in range(i+2, min(i+5, len(tokens))):\n",
        "                                if any(tokens[j].lower() in inds for entity, inds in self.context_indicators.items()):\n",
        "                                    break\n",
        "                                if any(tokens[j].lower() in inds for entity, inds in self.context_post_indicators.items()):\n",
        "                                    break\n",
        "                                context_labels[j] = f\"I-{entity_type}\"\n",
        "                                confidence_scores[j] = 0.7\n",
        "\n",
        "        # Post-context indicators\n",
        "        for i, token in enumerate(tokens):\n",
        "            if i > 0:  # Make sure we're not at the first token\n",
        "                for entity_type, indicators in self.context_post_indicators.items():\n",
        "                    if token.lower() in indicators:\n",
        "                        # The token before the indicator is likely the end of the entity\n",
        "                        if context_labels[i-1] == \"O\":\n",
        "                            context_labels[i-1] = f\"B-{entity_type}\"\n",
        "                            confidence_scores[i-1] = 0.7\n",
        "\n",
        "                            # Look backward for potential entity beginning (up to 3 tokens)\n",
        "                            start_idx = max(0, i-4)\n",
        "                            for j in range(i-2, start_idx-1, -1):\n",
        "                                if j < 0:\n",
        "                                    break\n",
        "                                if any(tokens[j].lower() in inds for entity, inds in self.context_indicators.items()):\n",
        "                                    break\n",
        "                                if context_labels[j] == \"O\":\n",
        "                                    context_labels[j] = f\"I-{entity_type}\"\n",
        "                                    confidence_scores[j] = 0.65\n",
        "\n",
        "                            # Fix the BIO scheme - first token should be B-\n",
        "                            for j in range(start_idx, i):\n",
        "                                if context_labels[j].startswith(\"I-\"):\n",
        "                                    prefix = context_labels[j][2:]\n",
        "                                    if j == 0 or context_labels[j-1] == \"O\" or context_labels[j-1][2:] != prefix:\n",
        "                                        context_labels[j] = f\"B-{prefix}\"\n",
        "\n",
        "        # Apply token-level confidence\n",
        "        for i, token in enumerate(tokens):\n",
        "            if token in self.token_confidence and context_labels[i] == \"O\":\n",
        "                entity_type, conf = self.token_confidence[token]\n",
        "                if conf > 0.8:  # Higher threshold for isolated tokens\n",
        "                    context_labels[i] = f\"B-{entity_type}\"\n",
        "                    confidence_scores[i] = conf * 0.8\n",
        "\n",
        "        return context_labels, confidence_scores\n",
        "\n",
        "    def apply_learned_corrections(self, tokens, base_labels):\n",
        "        \"\"\"Apply corrections based on learned misclassifications\"\"\"\n",
        "        custom_labels = base_labels.copy()\n",
        "        confidence_scores = [0.0] * len(tokens)\n",
        "        for i, label in enumerate(base_labels):\n",
        "            if label != \"O\":\n",
        "                confidence_scores[i] = 0.6\n",
        "\n",
        "        text = \" \".join(tokens)\n",
        "\n",
        "        for entity_type, patterns_with_counts in self.misclassification_corrections.items():\n",
        "            sorted_patterns = sorted(patterns_with_counts, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            for pattern, count in sorted_patterns:\n",
        "                try:\n",
        "                    for match in pattern.finditer(text):\n",
        "                        matched_text = match.group()\n",
        "                        span = self.find_token_span(tokens, matched_text)\n",
        "\n",
        "                        if span:\n",
        "                            start, end = span\n",
        "                            # Higher confidence for frequently missed patterns\n",
        "                            pattern_confidence = min(0.5 + (count / 20) * 0.4, 0.9)\n",
        "\n",
        "                            # Only override if current labels are \"O\" or lower confidence\n",
        "                            if custom_labels[start] == \"O\" or confidence_scores[start] < pattern_confidence:\n",
        "                                custom_labels[start] = f\"B-{entity_type}\"\n",
        "                                confidence_scores[start] = pattern_confidence\n",
        "\n",
        "                                for i in range(start + 1, end):\n",
        "                                    custom_labels[i] = f\"I-{entity_type}\"\n",
        "                                    confidence_scores[i] = pattern_confidence\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        return custom_labels, confidence_scores\n",
        "\n",
        "    def hybrid_entity_extraction(self, tokens):\n",
        "        \"\"\"Combine multiple methods for entity extraction using weighted confidence scores\"\"\"\n",
        "        # Get predictions from each method\n",
        "        spacy_labels, spacy_confidence = self.get_spacy_predictions(tokens)\n",
        "        regex_labels, regex_confidence = self.apply_regex_patterns(tokens)\n",
        "        context_labels, context_confidence = self.check_context_indicators(tokens)\n",
        "        custom_labels, custom_confidence = self.apply_learned_corrections(tokens, spacy_labels)\n",
        "\n",
        "        # Combine predictions with confidence weighting\n",
        "        final_labels = [\"O\"] * len(tokens)\n",
        "        confidence_info = [\"\"] * len(tokens)\n",
        "\n",
        "        for i in range(len(tokens)):\n",
        "            predictions = []\n",
        "\n",
        "            if custom_labels[i] != \"O\":\n",
        "                predictions.append((custom_labels[i], custom_confidence[i], \"custom\"))\n",
        "\n",
        "            if regex_labels[i] != \"O\":\n",
        "                predictions.append((regex_labels[i], regex_confidence[i], \"regex\"))\n",
        "\n",
        "            if context_labels[i] != \"O\":\n",
        "                predictions.append((context_labels[i], context_confidence[i], \"context\"))\n",
        "\n",
        "            if spacy_labels[i] != \"O\":\n",
        "                predictions.append((spacy_labels[i], spacy_confidence[i], \"spacy\"))\n",
        "\n",
        "            if predictions:\n",
        "                # Choose prediction with highest confidence\n",
        "                best_pred, best_conf, method = max(predictions, key=lambda x: x[1])\n",
        "                final_labels[i] = best_pred\n",
        "                confidence_info[i] = f\"{method}:{best_conf:.2f}\"\n",
        "            else:\n",
        "                confidence_info[i] = \"O:0.00\"\n",
        "\n",
        "        # Ensure BIO consistency\n",
        "        final_labels = self._ensure_bio_consistency(final_labels)\n",
        "\n",
        "        # Post-processing\n",
        "        final_labels = self._post_process_entities(tokens, final_labels)\n",
        "\n",
        "        return {\n",
        "            \"spacy\": spacy_labels,\n",
        "            \"regex\": regex_labels,\n",
        "            \"context\": context_labels,\n",
        "            \"custom\": custom_labels,\n",
        "            \"final\": final_labels,\n",
        "            \"confidence\": confidence_info\n",
        "        }\n",
        "\n",
        "    def _ensure_bio_consistency(self, labels):\n",
        "        \"\"\"Ensure BIO tagging is consistent\"\"\"\n",
        "        consistent_labels = labels.copy()\n",
        "\n",
        "        for i in range(1, len(labels)):\n",
        "            # Fix I- tags that don't follow matching B- or I- tags\n",
        "            if consistent_labels[i].startswith(\"I-\"):\n",
        "                entity_type = consistent_labels[i][2:]\n",
        "\n",
        "                # If previous tag is O or different entity, convert to B-\n",
        "                if (consistent_labels[i-1] == \"O\" or\n",
        "                    (consistent_labels[i-1].startswith(\"B-\") and consistent_labels[i-1][2:] != entity_type) or\n",
        "                    (consistent_labels[i-1].startswith(\"I-\") and consistent_labels[i-1][2:] != entity_type)):\n",
        "                    consistent_labels[i] = f\"B-{entity_type}\"\n",
        "\n",
        "        return consistent_labels\n",
        "\n",
        "    def _post_process_entities(self, tokens, labels):\n",
        "        \"\"\"Apply post-processing rules to improve entity consistency\"\"\"\n",
        "        processed_labels = labels.copy()\n",
        "\n",
        "        # Rule 1: Fix single-token entities with low-confidence between same-type entities\n",
        "        for i in range(1, len(tokens)-1):\n",
        "            if processed_labels[i-1].startswith((\"B-\", \"I-\")) and processed_labels[i+1].startswith((\"B-\", \"I-\")):\n",
        "                type_before = processed_labels[i-1][2:]\n",
        "                type_after = processed_labels[i+1][2:]\n",
        "\n",
        "                if type_before == type_after and processed_labels[i] == \"O\":\n",
        "                    processed_labels[i] = f\"I-{type_before}\"\n",
        "\n",
        "                # Fix B- at position i+1 if it's part of the same entity\n",
        "                if processed_labels[i+1].startswith(\"B-\") and type_before == type_after:\n",
        "                    processed_labels[i+1] = f\"I-{type_after}\"\n",
        "\n",
        "        # Rule 2: Fix adjacent entity boundaries\n",
        "        for i in range(len(tokens)-1):\n",
        "            if processed_labels[i].startswith(\"B-\") and processed_labels[i+1].startswith(\"B-\"):\n",
        "                type_current = processed_labels[i][2:]\n",
        "                type_next = processed_labels[i+1][2:]\n",
        "\n",
        "                # If they're the same type, convert the second B- to I-\n",
        "                if type_current == type_next:\n",
        "                    processed_labels[i+1] = f\"I-{type_next}\"\n",
        "\n",
        "        # Rule 3: Fix inconsistent I- tags\n",
        "        for i in range(1, len(tokens)):\n",
        "            if processed_labels[i].startswith(\"I-\"):\n",
        "                type_current = processed_labels[i][2:]\n",
        "\n",
        "                # If previous is B- or I- of different type, convert to B-\n",
        "                if processed_labels[i-1].startswith((\"B-\", \"I-\")):\n",
        "                    type_prev = processed_labels[i-1][2:]\n",
        "                    if type_prev != type_current:\n",
        "                        processed_labels[i] = f\"B-{type_current}\"\n",
        "\n",
        "        return processed_labels\n",
        "\n",
        "    def evaluate_on_dataset(self, dataset_split=\"test\", limit=None):\n",
        "        \"\"\"Evaluate the NER system on a dataset split\"\"\"\n",
        "        print(f\"Evaluating on {dataset_split} set...\")\n",
        "\n",
        "        split_data = dataset[dataset_split]\n",
        "        id_to_label = split_data.features[\"ner_tags\"].feature.int2str\n",
        "\n",
        "        # Initialize metrics tracking\n",
        "        true_predictions = []\n",
        "        true_labels = []\n",
        "        errors = []\n",
        "        entity_errors = defaultdict(lambda: {\"missed\": 0, \"wrong_type\": 0, \"partial\": 0})\n",
        "        confusion_matrix = {\n",
        "            \"PER\": {\"PER\": 0, \"LOC\": 0, \"ORG\": 0, \"O\": 0},\n",
        "            \"LOC\": {\"PER\": 0, \"LOC\": 0, \"ORG\": 0, \"O\": 0},\n",
        "            \"ORG\": {\"PER\": 0, \"LOC\": 0, \"ORG\": 0, \"O\": 0},\n",
        "            \"O\": {\"PER\": 0, \"LOC\": 0, \"ORG\": 0, \"O\": 0}\n",
        "        }\n",
        "\n",
        "        # Process each example\n",
        "        max_examples = min(limit, len(split_data)) if limit else len(split_data)\n",
        "        for idx, (tokens, tags) in enumerate(tqdm(zip(split_data[\"tokens\"], split_data[\"ner_tags\"]),\n",
        "                                                total=max_examples,\n",
        "                                                desc=f\"Evaluating {dataset_split}\")):\n",
        "            if limit and idx >= limit:\n",
        "                break\n",
        "\n",
        "            # Convert numeric tags to string labels\n",
        "            string_tags = [id_to_label(tag) for tag in tags]\n",
        "\n",
        "            # Ensure gold labels are in proper BIO format\n",
        "            string_tags = self._ensure_bio_consistency(string_tags)\n",
        "            true_labels.append(string_tags)\n",
        "\n",
        "            # Get predictions\n",
        "            results = self.hybrid_entity_extraction(tokens)\n",
        "            final_preds = results[\"final\"]\n",
        "\n",
        "            # Ensure predictions are in proper BIO format\n",
        "            final_preds = self._ensure_bio_consistency(final_preds)\n",
        "            true_predictions.append(final_preds)\n",
        "\n",
        "            # Record errors and confusion\n",
        "            error_examples = []\n",
        "            for i, (token, true, pred) in enumerate(zip(tokens, string_tags, final_preds)):\n",
        "                true_type = true[2:] if \"-\" in true else \"O\"\n",
        "                pred_type = pred[2:] if \"-\" in pred else \"O\"\n",
        "\n",
        "                # Update confusion matrix\n",
        "                if true_type in confusion_matrix and pred_type in confusion_matrix[true_type]:\n",
        "                    confusion_matrix[true_type][pred_type] += 1\n",
        "\n",
        "                # Record errors\n",
        "                if true != pred:\n",
        "                    # Get context (3 tokens before and after)\n",
        "                    start_idx = max(0, i - 3)\n",
        "                    end_idx = min(len(tokens), i + 4)\n",
        "                    context = \" \".join(tokens[start_idx:end_idx])\n",
        "\n",
        "                    # Determine error type\n",
        "                    error_type = \"other\"\n",
        "                    if true.startswith(\"B-\") and pred == \"O\":\n",
        "                        error_type = \"missed\"\n",
        "                        entity_errors[true_type][\"missed\"] += 1\n",
        "                    elif true.startswith(\"B-\") and pred.startswith(\"B-\"):\n",
        "                        error_type = \"wrong_type\"\n",
        "                        entity_errors[true_type][\"wrong_type\"] += 1\n",
        "                    elif true.startswith(\"I-\") and (pred == \"O\" or pred.startswith(\"B-\")):\n",
        "                        error_type = \"partial\"\n",
        "                        entity_entity = true[2:]\n",
        "                        entity_errors[entity_entity][\"partial\"] += 1\n",
        "\n",
        "                    error_examples.append({\n",
        "                        \"token\": token,\n",
        "                        \"true\": true,\n",
        "                        \"predicted\": pred,\n",
        "                        \"context\": context,\n",
        "                        \"error_type\": error_type\n",
        "                    })\n",
        "\n",
        "            if error_examples:\n",
        "                errors.extend(error_examples)\n",
        "\n",
        "        # Calculate metrics using seqeval\n",
        "        metrics = classification_report(\n",
        "            true_labels, true_predictions,\n",
        "            digits=4, output_dict=True,\n",
        "            mode='strict', scheme=IOB2Scheme  # Use the class, not a string\n",
        "        )\n",
        "\n",
        "        # Store results for later analysis\n",
        "        self.true_labels = true_labels\n",
        "        self.true_predictions = true_predictions\n",
        "        self.error_examples = errors\n",
        "        self.confusion_matrix = confusion_matrix\n",
        "        self.entity_errors = entity_errors\n",
        "        self.performance_metrics = metrics\n",
        "\n",
        "        # Extract overall metrics\n",
        "        results = {\n",
        "            \"overall_precision\": metrics[\"micro avg\"][\"precision\"],\n",
        "            \"overall_recall\": metrics[\"micro avg\"][\"recall\"],\n",
        "            \"overall_f1\": metrics[\"micro avg\"][\"f1-score\"],\n",
        "        }\n",
        "\n",
        "        # Extract entity-specific metrics\n",
        "        for entity_type in self.allowed_entities:\n",
        "            entity_key = f\"B-{entity_type}\"\n",
        "            if entity_key in metrics:\n",
        "                results[entity_type] = {\n",
        "                    \"precision\": metrics[entity_key][\"precision\"],\n",
        "                    \"recall\": metrics[entity_key][\"recall\"],\n",
        "                    \"f1\": metrics[entity_key][\"f1-score\"],\n",
        "                    \"support\": metrics[entity_key][\"support\"]\n",
        "                }\n",
        "\n",
        "        return results\n",
        "\n",
        "    def show_detailed_analysis(self):\n",
        "        \"\"\"Display classification report using seqeval in the specified format\"\"\"\n",
        "        if not hasattr(self, 'true_labels') or not hasattr(self, 'true_predictions'):\n",
        "            print(\"No evaluation results available. Run evaluate_on_dataset() first.\")\n",
        "            return\n",
        "\n",
        "        # Generate the classification report using seqeval\n",
        "        report = classification_report(\n",
        "            self.true_labels,\n",
        "            self.true_predictions,\n",
        "            digits=4,\n",
        "            output_dict=True\n",
        "        )\n",
        "\n",
        "        # Print the classification report header\n",
        "        print(\"\\nEntity      Precision   Recall   F1 score   Support\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # Define the order of entities to display\n",
        "        entity_order = ['LOC', 'ORG', 'PER']\n",
        "\n",
        "        # Print metrics for each entity type\n",
        "        for entity in entity_order:\n",
        "            entity_key = f\"{entity}\"\n",
        "            if entity_key in report:\n",
        "                metrics = report[entity_key]\n",
        "                print(f\"{entity:<10} {metrics['precision']:>9.4f} {metrics['recall']:>8.4f} {metrics['f1-score']:>9.4f} {metrics['support']:>9}\")\n",
        "\n",
        "        # Print overall metrics\n",
        "        print(\"\\nOverall metrics:\")\n",
        "        print(f\"Precision: {report['micro avg']['precision']:.4f}\")\n",
        "        print(f\"Recall:    {report['micro avg']['recall']:.4f}\")\n",
        "        print(f\"F1-score:  {report['micro avg']['f1-score']:.4f}\")\n",
        "        print(f\"Support:   {report['micro avg']['support']}\")\n",
        "\n",
        "        # Print error types by entity\n",
        "        print(\"\\nError Types by Entity:\")\n",
        "        for entity_type, counts in self.entity_errors.items():\n",
        "            total = sum(counts.values())\n",
        "            if total > 0:\n",
        "                print(f\"{entity_type}:\")\n",
        "                for error_type, count in counts.items():\n",
        "                    print(f\"  {error_type}: {count} ({count/total:.1%})\")\n",
        "\n",
        "        # Print example errors\n",
        "        print(\"\\nExample Errors (first 10):\")\n",
        "        for error in self.error_examples[:10]:\n",
        "            print(f\"Token: {error['token']}\")\n",
        "            print(f\"True: {error['true']}, Predicted: {error['predicted']}\")\n",
        "            print(f\"Context: {error['context']}\")\n",
        "            print(f\"Error Type: {error['error_type']}\\n\")\n",
        "\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Load dataset\n",
        "    dataset = load_dataset(\"wikiann\", \"te\")\n",
        "\n",
        "    # Initialize and run NER system\n",
        "    ner = TeluguNER()\n",
        "    ner.load_correction_patterns_from_training(dataset)\n",
        "    metrics = ner.evaluate_on_dataset(limit=1000)\n",
        "    ner.show_detailed_analysis()\n",
        "\n",
        "    # Print final results\n",
        "    print(\"\\n=== Final Evaluation Results ===\")\n",
        "    print(f\"Overall F1: {metrics['overall_f1']:.4f}\")\n",
        "    print(f\"Precision: {metrics['overall_precision']:.4f}\")\n",
        "    print(f\"Recall: {metrics['overall_recall']:.4f}\")\n",
        "\n",
        "    for entity_type in ner.allowed_entities:\n",
        "        if entity_type in metrics:\n",
        "            print(f\"\\n{entity_type} Metrics:\")\n",
        "            print(f\"F1: {metrics[entity_type]['f1']:.4f}\")\n",
        "            print(f\"Precision: {metrics[entity_type]['precision']:.4f}\")\n",
        "            print(f\"Recall: {metrics[entity_type]['recall']:.4f}\")\n",
        "            print(f\"Support: {metrics[entity_type]['support']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6T6A_C_yDwQN",
        "outputId": "221e4936-0e53-42d1-c867-ed26778bb823"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning correction patterns from training data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Analyzing training data: 100%|██████████| 1000/1000 [00:02<00:00, 477.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity statistics in training data: {'LOC': 493, 'ORG': 347, 'PER': 364}\n",
            "Created 155 correction patterns from training data\n",
            "Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating test: 100%|██████████| 1000/1000 [00:02<00:00, 380.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Entity      Precision   Recall   F1 score   Support\n",
            "--------------------------------------------------\n",
            "LOC           0.2982   0.1889    0.2313       450\n",
            "ORG           0.1305   0.1824    0.1521       340\n",
            "PER           0.5357   0.2362    0.3279       381\n",
            "\n",
            "Overall metrics:\n",
            "Precision: 0.2554\n",
            "Recall:    0.2024\n",
            "F1-score:  0.2258\n",
            "Support:   1171\n",
            "\n",
            "Error Types by Entity:\n",
            "ORG:\n",
            "  missed: 203 (34.2%)\n",
            "  wrong_type: 24 (4.0%)\n",
            "  partial: 366 (61.7%)\n",
            "LOC:\n",
            "  missed: 274 (69.9%)\n",
            "  wrong_type: 4 (1.0%)\n",
            "  partial: 114 (29.1%)\n",
            "PER:\n",
            "  missed: 236 (49.7%)\n",
            "  wrong_type: 18 (3.8%)\n",
            "  partial: 221 (46.5%)\n",
            "\n",
            "Example Errors (first 10):\n",
            "Token: ల\n",
            "True: I-ORG, Predicted: O\n",
            "Context: ప్రపంచ మస్జిద్ ల జాబితా\n",
            "Error Type: partial\n",
            "\n",
            "Token: జాబితా\n",
            "True: I-ORG, Predicted: O\n",
            "Context: ప్రపంచ మస్జిద్ ల జాబితా\n",
            "Error Type: partial\n",
            "\n",
            "Token: EU\n",
            "True: O, Predicted: B-ORG\n",
            "Context: EU BY BLR 112\n",
            "Error Type: other\n",
            "\n",
            "Token: BY\n",
            "True: O, Predicted: I-ORG\n",
            "Context: EU BY BLR 112 బెలారస్\n",
            "Error Type: other\n",
            "\n",
            "Token: బెలారస్\n",
            "True: B-LOC, Predicted: O\n",
            "Context: BY BLR 112 బెలారస్\n",
            "Error Type: missed\n",
            "\n",
            "Token: చెక్\n",
            "True: B-LOC, Predicted: O\n",
            "Context: ' '' చెక్ రిపబ్లిక్ '' '\n",
            "Error Type: missed\n",
            "\n",
            "Token: రిపబ్లిక్\n",
            "True: I-LOC, Predicted: O\n",
            "Context: ' '' చెక్ రిపబ్లిక్ '' '\n",
            "Error Type: partial\n",
            "\n",
            "Token: రాయల్\n",
            "True: B-ORG, Predicted: B-LOC\n",
            "Context: రాయల్ సొసైటీ లో సభ్యత్వం\n",
            "Error Type: wrong_type\n",
            "\n",
            "Token: సొసైటీ\n",
            "True: I-ORG, Predicted: I-LOC\n",
            "Context: రాయల్ సొసైటీ లో సభ్యత్వం పొందిన\n",
            "Error Type: other\n",
            "\n",
            "Token: మొట్టమొదటి\n",
            "True: O, Predicted: B-LOC\n",
            "Context: లో సభ్యత్వం పొందిన మొట్టమొదటి భారతీయుడు -- జగదీశ్\n",
            "Error Type: other\n",
            "\n",
            "\n",
            "=== Final Evaluation Results ===\n",
            "Overall F1: 0.2258\n",
            "Precision: 0.2554\n",
            "Recall: 0.2024\n"
          ]
        }
      ]
    }
  ]
}