{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text",
        "state": {}
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shriyatha/Named_Entity_Recognition/blob/main/BERT_BASED_NER_English.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poZ6x1woyxyD",
        "outputId": "48827d30-ff9c-45f5-9e75-b0ad63f86747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# BERT-based Named Entity Recognition (NER) on CoNLL-2003 Dataset\n",
        "# =============================================================\n",
        "\n",
        "# Install required packages\n",
        "!pip install transformers datasets evaluate seqeval torch tqdm matplotlib pandas seaborn -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8RawTwk0zLf0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import (\n",
        "    BertTokenizerFast,\n",
        "    BertForTokenClassification,\n",
        "    DataCollatorForTokenClassification,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "from torch.optim import AdamW\n",
        "from datasets import load_dataset\n",
        "from evaluate import load\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukzCoEJgzXw-",
        "outputId": "ef61d0ad-c552-4f11-dd1a-d465059a08b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Set random seeds for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# Check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9C0UR4azeuS",
        "outputId": "4f52d85f-118c-427c-fa98-2db1561af8f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== Data Loading and Exploration ====\n",
            "\n",
            "Dataset splits:\n",
            "- train: 14041 examples\n",
            "- validation: 3250 examples\n",
            "- test: 3453 examples\n",
            "\n",
            "Dataset features: {'id': Value(dtype='string', id=None), 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'pos_tags': Sequence(feature=ClassLabel(names=['\"', \"''\", '#', '$', '(', ')', ',', '.', ':', '``', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'NN|SYM', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB'], id=None), length=-1, id=None), 'chunk_tags': Sequence(feature=ClassLabel(names=['O', 'B-ADJP', 'I-ADJP', 'B-ADVP', 'I-ADVP', 'B-CONJP', 'I-CONJP', 'B-INTJ', 'I-INTJ', 'B-LST', 'I-LST', 'B-NP', 'I-NP', 'B-PP', 'I-PP', 'B-PRT', 'I-PRT', 'B-SBAR', 'I-SBAR', 'B-UCP', 'I-UCP', 'B-VP', 'I-VP'], id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)}\n"
          ]
        }
      ],
      "source": [
        "# 1. Data Loading and Exploration\n",
        "# ==============================\n",
        "print(\"\\n==== Data Loading and Exploration ====\")\n",
        "# Load dataset and metric\n",
        "dataset = load_dataset(\"conll2003\")\n",
        "metric = load(\"seqeval\")\n",
        "\n",
        "# Basic dataset info\n",
        "print(\"\\nDataset splits:\")\n",
        "for split in dataset.keys():\n",
        "    print(f\"- {split}: {dataset[split].num_rows} examples\")\n",
        "\n",
        "# Examine data structure\n",
        "print(\"\\nDataset features:\", dataset[\"train\"].features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "90311824432d44268518d8f70f936848",
            "345bf1b73c8c44c8a108e8ba90289919",
            "c1a132d8957240da881b70913a9a5d60",
            "16cc9bd40ac94ca49e3aa87d4ac40963",
            "7c05da75f01d4060af3c2fe72c91af33",
            "3cfd5085ca6f49948afea5b99055f01a",
            "955c33124e424c9680dd2e8d736c354a",
            "6fbd3aa253c442b8ae6969f99026c62e",
            "26a85bf75c53491898b7040a19405e3d",
            "d62caa0dc1894d8b86b186e796bfbf06",
            "27252b9158f94d9091be9dd2f7db0452"
          ]
        },
        "id": "ueoT49n9zzfR",
        "outputId": "b48f9a50-95f2-4958-e9e4-d2ed48b79cd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== Data Preprocessing ====\n",
            "Tokenizing dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90311824432d44268518d8f70f936848"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization completed in 0.89 seconds\n"
          ]
        }
      ],
      "source": [
        "# 2. Data Preprocessing\n",
        "# ====================\n",
        "print(\"\\n==== Data Preprocessing ====\")\n",
        "# Initialize tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "# Define label_list\n",
        "label_list = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
        "\n",
        "# Preprocess function to align labels with tokens\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"],\n",
        "        truncation=True,\n",
        "        is_split_into_words=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)  # Special tokens get -100\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])  # First token of word\n",
        "            else:\n",
        "                label_ids.append(-100)  # Subsequent tokens of word get -100\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "print(\"Tokenizing dataset...\")\n",
        "start_time = time.time()\n",
        "# Tokenize dataset\n",
        "tokenized_datasets = dataset.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    remove_columns=dataset[\"train\"].column_names\n",
        ")\n",
        "tokenization_time = time.time() - start_time\n",
        "print(f\"Tokenization completed in {tokenization_time:.2f} seconds\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4EboZ15z8xd",
        "outputId": "8b2d3fc4-7247-4132-87bb-82f34190a675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== Model Setup ====\n",
            "Using batch size: 16\n",
            "\n",
            "Initializing BERT model for token classification...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model architecture:\n",
            "BertForTokenClassification\n",
            "Total parameters: 107,726,601\n",
            "Trainable parameters: 107,726,601\n",
            "Non-trainable parameters: 0\n"
          ]
        }
      ],
      "source": [
        "# 3. Model Setup\n",
        "# =============\n",
        "print(\"\\n==== Model Setup ====\")\n",
        "# Create data collator\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 16\n",
        "print(f\"Using batch size: {batch_size}\")\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"train\"],\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "val_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"validation\"],\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"test\"],\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Initialize model\n",
        "print(\"\\nInitializing BERT model for token classification...\")\n",
        "model = BertForTokenClassification.from_pretrained(\n",
        "    \"bert-base-cased\",\n",
        "    num_labels=len(label_list),\n",
        "    id2label={i: label for i, label in enumerate(label_list)},\n",
        "    label2id={label: i for i, label in enumerate(label_list)}\n",
        ").to(device)\n",
        "\n",
        "# Print model architecture\n",
        "print(\"\\nModel architecture:\")\n",
        "print(model.__class__.__name__)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"Non-trainable parameters: {total_params - trainable_params:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yf448Ns0Hv5",
        "outputId": "5a47b5b5-6ae2-401b-e243-e748dffcaadd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== Training Setup ====\n",
            "Learning rate: 2e-05\n",
            "Epochs: 5\n",
            "Weight decay: 0.01\n",
            "Warmup steps: 0\n"
          ]
        }
      ],
      "source": [
        "# 4. Training Setup\n",
        "# ================\n",
        "print(\"\\n==== Training Setup ====\")\n",
        "# Hyperparameters\n",
        "learning_rate = 2e-5\n",
        "epochs = 5\n",
        "weight_decay = 0.01\n",
        "warmup_steps = 0\n",
        "print(f\"Learning rate: {learning_rate}\")\n",
        "print(f\"Epochs: {epochs}\")\n",
        "print(f\"Weight decay: {weight_decay}\")\n",
        "print(f\"Warmup steps: {warmup_steps}\")\n",
        "\n",
        "# Optimizer and scheduler\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=learning_rate,\n",
        "    weight_decay=weight_decay\n",
        ")\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=warmup_steps,\n",
        "    num_training_steps=total_steps\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAGlcNSQ0Orz",
        "outputId": "f44cae88-9353-45e9-f556-3a96b48d67f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== Training Loop ====\n",
            "\n",
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5 [Training]: 100%|██████████| 878/878 [05:16<00:00,  2.77it/s]\n",
            "Epoch 1/5 [Validation]: 100%|██████████| 204/204 [00:25<00:00,  8.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/5 completed in 342.35 seconds\n",
            "Training Loss: 0.1127\n",
            "Validation F1: 0.9254\n",
            "Validation Precision: 0.9206\n",
            "Validation Recall: 0.9303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5 [Training]: 100%|██████████| 878/878 [05:16<00:00,  2.77it/s]\n",
            "Epoch 2/5 [Validation]: 100%|██████████| 204/204 [00:25<00:00,  8.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/5 completed in 342.64 seconds\n",
            "Training Loss: 0.0279\n",
            "Validation F1: 0.9419\n",
            "Validation Precision: 0.9390\n",
            "Validation Recall: 0.9447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5 [Training]: 100%|██████████| 878/878 [05:16<00:00,  2.77it/s]\n",
            "Epoch 3/5 [Validation]: 100%|██████████| 204/204 [00:24<00:00,  8.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3/5 completed in 342.25 seconds\n",
            "Training Loss: 0.0137\n",
            "Validation F1: 0.9431\n",
            "Validation Precision: 0.9382\n",
            "Validation Recall: 0.9481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5 [Training]: 100%|██████████| 878/878 [05:16<00:00,  2.77it/s]\n",
            "Epoch 4/5 [Validation]: 100%|██████████| 204/204 [00:24<00:00,  8.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4/5 completed in 342.38 seconds\n",
            "Training Loss: 0.0081\n",
            "Validation F1: 0.9468\n",
            "Validation Precision: 0.9427\n",
            "Validation Recall: 0.9510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5 [Training]: 100%|██████████| 878/878 [05:16<00:00,  2.77it/s]\n",
            "Epoch 5/5 [Validation]: 100%|██████████| 204/204 [00:24<00:00,  8.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5/5 completed in 342.44 seconds\n",
            "Training Loss: 0.0052\n",
            "Validation F1: 0.9491\n",
            "Validation Precision: 0.9452\n",
            "Validation Recall: 0.9530\n",
            "\n",
            "Training completed in 1712.07 seconds (28.53 minutes)\n"
          ]
        }
      ],
      "source": [
        "# 5. Training Loop\n",
        "# ==============\n",
        "print(\"\\n==== Training Loop ====\")\n",
        "# Helper function for evaluation\n",
        "def evaluate(dataloader, desc=\"Evaluating\"):\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "    for batch in tqdm(dataloader, desc=desc):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "            logits = outputs.logits\n",
        "            batch_preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "            batch_labels = batch[\"labels\"].cpu().numpy()\n",
        "        for preds, labels in zip(batch_preds, batch_labels):\n",
        "            # Filter out ignored index (-100)\n",
        "            true_indices = [i for i, l in enumerate(labels) if l != -100]\n",
        "            true_labels.append([label_list[labels[i]] for i in true_indices])\n",
        "            predictions.append([label_list[preds[i]] for i in true_indices])\n",
        "    results = metric.compute(predictions=predictions, references=true_labels)\n",
        "    return results, predictions, true_labels\n",
        "\n",
        "# Store metrics for plotting\n",
        "train_losses = []\n",
        "val_f1_scores = []\n",
        "print(\"\\nStarting training...\")\n",
        "start_training_time = time.time()\n",
        "for epoch in range(epochs):\n",
        "    epoch_start_time = time.time()\n",
        "    # Training\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{epochs} [Training]\"):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # Validation\n",
        "    val_results, _, _ = evaluate(val_dataloader, desc=f\"Epoch {epoch+1}/{epochs} [Validation]\")\n",
        "    val_f1_scores.append(val_results[\"overall_f1\"])\n",
        "    epoch_time = time.time() - epoch_start_time\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"\\nEpoch {epoch+1}/{epochs} completed in {epoch_time:.2f} seconds\")\n",
        "    print(f\"Training Loss: {avg_train_loss:.4f}\")\n",
        "    print(f\"Validation F1: {val_results['overall_f1']:.4f}\")\n",
        "    print(f\"Validation Precision: {val_results['overall_precision']:.4f}\")\n",
        "    print(f\"Validation Recall: {val_results['overall_recall']:.4f}\")\n",
        "\n",
        "total_training_time = time.time() - start_training_time\n",
        "print(f\"\\nTraining completed in {total_training_time:.2f} seconds ({total_training_time/60:.2f} minutes)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "8Fvy5c4U0n2R"
      },
      "outputs": [],
      "source": [
        "# Plot training progress\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, epochs + 1), train_losses, marker='o')\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, epochs + 1), val_f1_scores, marker='o', color='green')\n",
        "plt.title(\"Validation F1 Score\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"F1 Score\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_progress.png')\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccz97Agi0qT1",
        "outputId": "6192f422-b780-46ff-c25a-75aad77bb25f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== Test Evaluation and Analysis ====\n",
            "Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 216/216 [00:26<00:00,  8.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Results:\n",
            "Accuracy: 0.9832\n",
            "Precision: 0.9097\n",
            "Recall: 0.9231\n",
            "F1 Score: 0.9164\n",
            "\n",
            "Per-Entity Type Metrics:\n",
            "LOC:\n",
            " Precision: 0.9335\n",
            " Recall: 0.9358\n",
            " F1: 0.9347\n",
            " Support: 1666 entities\n",
            "MISC:\n",
            " Precision: 0.7791\n",
            " Recall: 0.8191\n",
            " F1: 0.7986\n",
            " Support: 702 entities\n",
            "ORG:\n",
            " Precision: 0.8897\n",
            " Recall: 0.9181\n",
            " F1: 0.9037\n",
            " Support: 1661 entities\n",
            "PER:\n",
            " Precision: 0.9664\n",
            " Recall: 0.9604\n",
            " F1: 0.9634\n",
            " Support: 1615 entities\n"
          ]
        }
      ],
      "source": [
        "# 6. Test Evaluation and Analysis\n",
        "# ==============================\n",
        "print(\"\\n==== Test Evaluation and Analysis ====\")\n",
        "print(\"Evaluating on test set...\")\n",
        "test_results, test_predictions, test_true_labels = evaluate(test_dataloader, \"Testing\")\n",
        "\n",
        "# Print overall metrics\n",
        "print(\"\\nTest Results:\")\n",
        "print(f\"Accuracy: {test_results['overall_accuracy']:.4f}\")\n",
        "print(f\"Precision: {test_results['overall_precision']:.4f}\")\n",
        "print(f\"Recall: {test_results['overall_recall']:.4f}\")\n",
        "print(f\"F1 Score: {test_results['overall_f1']:.4f}\")\n",
        "\n",
        "# Print per-entity metrics\n",
        "print(\"\\nPer-Entity Type Metrics:\")\n",
        "entity_results = {}\n",
        "for key in sorted(test_results.keys()):\n",
        "    if key not in ['overall_accuracy', 'overall_precision', 'overall_recall', 'overall_f1']:\n",
        "        entity_results[key] = {\n",
        "            'precision': test_results[key]['precision'],\n",
        "            'recall': test_results[key]['recall'],\n",
        "            'f1': test_results[key]['f1'],\n",
        "            'number': test_results[key]['number']\n",
        "        }\n",
        "        print(f\"{key}:\")\n",
        "        print(f\" Precision: {test_results[key]['precision']:.4f}\")\n",
        "        print(f\" Recall: {test_results[key]['recall']:.4f}\")\n",
        "        print(f\" F1: {test_results[key]['f1']:.4f}\")\n",
        "        print(f\" Support: {test_results[key]['number']} entities\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPlXDBxpF98lLtduPXZNNWN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "90311824432d44268518d8f70f936848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_345bf1b73c8c44c8a108e8ba90289919",
              "IPY_MODEL_c1a132d8957240da881b70913a9a5d60",
              "IPY_MODEL_16cc9bd40ac94ca49e3aa87d4ac40963"
            ],
            "layout": "IPY_MODEL_7c05da75f01d4060af3c2fe72c91af33"
          }
        },
        "345bf1b73c8c44c8a108e8ba90289919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cfd5085ca6f49948afea5b99055f01a",
            "placeholder": "​",
            "style": "IPY_MODEL_955c33124e424c9680dd2e8d736c354a",
            "value": "Map: 100%"
          }
        },
        "c1a132d8957240da881b70913a9a5d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fbd3aa253c442b8ae6969f99026c62e",
            "max": 3250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26a85bf75c53491898b7040a19405e3d",
            "value": 3250
          }
        },
        "16cc9bd40ac94ca49e3aa87d4ac40963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d62caa0dc1894d8b86b186e796bfbf06",
            "placeholder": "​",
            "style": "IPY_MODEL_27252b9158f94d9091be9dd2f7db0452",
            "value": " 3250/3250 [00:00&lt;00:00, 3999.01 examples/s]"
          }
        },
        "7c05da75f01d4060af3c2fe72c91af33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cfd5085ca6f49948afea5b99055f01a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "955c33124e424c9680dd2e8d736c354a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fbd3aa253c442b8ae6969f99026c62e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26a85bf75c53491898b7040a19405e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d62caa0dc1894d8b86b186e796bfbf06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27252b9158f94d9091be9dd2f7db0452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
